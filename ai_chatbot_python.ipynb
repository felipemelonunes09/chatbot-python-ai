{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/felipemelonunes09/llm-chatbot-python/blob/collab/ai_chatbot_python.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o6dPNvadH_hY"
      },
      "source": [
        "# Aplicão LLM\n",
        "\n",
        "Este notebook apresentará um guia abrangente para a construção de uma aplicação utilizando uma LLM. O processo envolve o uso de carregadores de documentos, embeddings, bancos de dados vetoriais e templates de prompt, utilizando principalmente o LangChain e a API da OpenAI. Esta abordagem enfatiza o uso da injeção de contexto em vez do fine-tuning, para conseguir respostas mais coerentes com o contexto fornecido.\n",
        "\n",
        "## Injeção de Contexto\n",
        "\n",
        "Ao invés de utilizar fine-tuning, essa abordagem é uma solução mais eficiente para a aplicação de conhecimento específico de domínio em LLMs. Os modelos pré-treinados estão restritos aos dados com os quais foram treinados, enquanto a injeção de contexto insere o contexto necessário dentro do próprio prompt, resultando em respostas mais precisas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V1FWmQoQILnO"
      },
      "source": [
        "## 1. Carregando Documentos\n",
        "\n",
        "Não utilizaremos nenhum carregador do LangChain. Em vez disso, faremos uso exclusivo da biblioteca BeautifulSoup para realizar o scraping de uma página web e extrair as informações necessárias para a nossa aplicação.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HTz6BXNfOeOG"
      },
      "source": [
        "### Instalando Dependências\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "ZOo4vWkKNcZq",
        "outputId": "4d77ef85-e9ae-40fb-887b-2d9e9926612b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (4.12.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4) (2.5)\n"
          ]
        }
      ],
      "source": [
        "pip install beautifulsoup4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "XE6y_GtvPePL",
        "outputId": "b92cdc9c-5d0d-4752-d42e-7d0dd07fa39d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2024.7.4)\n"
          ]
        }
      ],
      "source": [
        "pip install requests"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wChVQQO5OnJo"
      },
      "source": [
        "### Código\n",
        "\n",
        "Realizaremos a requisição e transferiremos a resposta para um objeto da biblioteca BeautifulSoup."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Q-iRRhwBOrut",
        "outputId": "995ea713-ee07-4616-ed5b-03133a358b70"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "GPT-4 - Wikipedia\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Jump to content\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Main menu\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Main menu\n",
            "move to sidebar\n",
            "hide\n",
            "\n",
            "\n",
            "\n",
            "\t\tNavigation\n",
            "\t\n",
            "\n",
            "\n",
            "Main pageContentsCurrent eventsRandom articleAbout WikipediaContact usDonate\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\t\tContribute\n",
            "\t\n",
            "\n",
            "\n",
            "HelpLearn to editCommunity portalRecent changesUpload file\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Search\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Search\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Appearance\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Create account\n",
            "\n",
            "Log in\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Personal tools\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " Create account Log in\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\t\tPages for logged out editors learn more\n",
            "\n",
            "\n",
            "\n",
            "ContributionsTalk\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Contents\n",
            "move to sidebar\n",
            "hide\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "(Top)\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "1\n",
            "Background\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "2\n",
            "Capabilities\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Toggle Capabilities subsection\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "2.1\n",
            "GPT-4o\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "2.2\n",
            "Aptitude on standardized tests\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "2.3\n",
            "Medical applications\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3\n",
            "Limitations\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Toggle Limitations subsection\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3.1\n",
            "Bias\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "4\n",
            "Training\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "5\n",
            "Alignment\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "6\n",
            "Usage\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Toggle Usage subsection\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "6.1\n",
            "ChatGPT\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "6.2\n",
            "Microsoft Copilot\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "6.3\n",
            "Other usage\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "7\n",
            "Reception\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Toggle Reception subsection\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "7.1\n",
            "Concerns\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "7.2\n",
            "Criticisms of transparency\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "8\n",
            "See also\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "9\n",
            "References\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Toggle the table of contents\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "GPT-4\n",
            "\n",
            "\n",
            "\n",
            "30 languages\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "العربيةAzərbaycancaবাংলাCatalàČeštinaDeutschEestiΕλληνικάEspañolفارسیFrançais한국어Հայերենहिन्दीItalianoעבריתKiswahiliLatviešuNederlands日本語PortuguêsQaraqalpaqshaRuna SimiРусскийСаха тылаSuomiTürkçeУкраїнськаTiếng Việt中文\n",
            "\n",
            "Edit links\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ArticleTalk\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "English\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ReadEditView history\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Tools\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Tools\n",
            "move to sidebar\n",
            "hide\n",
            "\n",
            "\n",
            "\n",
            "\t\tActions\n",
            "\t\n",
            "\n",
            "\n",
            "ReadEditView history\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\t\tGeneral\n",
            "\t\n",
            "\n",
            "\n",
            "What links hereRelated changesUpload fileSpecial pagesPermanent linkPage informationCite this pageGet shortened URLDownload QR codeWikidata item\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\t\tPrint/export\n",
            "\t\n",
            "\n",
            "\n",
            "Download as PDFPrintable version\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Appearance\n",
            "move to sidebar\n",
            "hide\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "From Wikipedia, the free encyclopedia\n",
            "\n",
            "\n",
            "2023 text-generating language model\n",
            "\n",
            "\n",
            "Generative Pre-trained Transformer 4 (GPT-4)Developer(s)OpenAIInitial releaseMarch 14, 2023; 16 months ago (2023-03-14)PredecessorGPT-3.5SuccessorGPT-4oType\n",
            "Multimodal\n",
            "Large language model\n",
            "Generative pre-trained transformer\n",
            "Foundation model\n",
            "LicenseProprietaryWebsiteopenai.com/gpt-4 \n",
            "Generative Pre-trained Transformer 4 (GPT-4) is a multimodal large language model created by OpenAI, and the fourth in its series of GPT foundation models.[1] It was launched on March 14, 2023,[1] and made publicly available via the paid chatbot product ChatGPT Plus, via OpenAI's API, and via the free chatbot Microsoft Copilot.[2]  As a transformer-based model, GPT-4 uses a paradigm where pre-training using both public data and \"data licensed from third-party providers\" is used to predict the next token. After this step, the model was then fine-tuned with reinforcement learning feedback from humans and AI for human alignment and policy compliance.[3]: 2 \n",
            "Observers reported that the iteration of ChatGPT using GPT-4 was an improvement on the previous iteration based on GPT-3.5, with the caveat that GPT-4 retains some of the problems with earlier revisions.[4] GPT-4, equipped with vision capabilities (GPT-4V),[5] is capable of taking images as input on ChatGPT.[6] OpenAI has declined to reveal various technical details and statistics about GPT-4, such as the precise size of the model.[7]\n",
            "\n",
            "\n",
            "Background[edit]\n",
            "Further information: GPT-3 § Background, and GPT-2 § Background\n",
            "\n",
            "Part of a series onMachine learningand data mining\n",
            "Paradigms\n",
            "Supervised learning\n",
            "Unsupervised learning\n",
            "Semi-supervised learning\n",
            "Self-supervised learning\n",
            "Reinforcement learning\n",
            "Meta-learning\n",
            "Online learning\n",
            "Batch learning\n",
            "Curriculum learning\n",
            "Rule-based learning\n",
            "Neuro-symbolic AI\n",
            "Neuromorphic engineering\n",
            "Quantum machine learning\n",
            "\n",
            "Problems\n",
            "Classification\n",
            "Generative modeling\n",
            "Regression\n",
            "Clustering\n",
            "Dimensionality reduction\n",
            "Density estimation\n",
            "Anomaly detection\n",
            "Data cleaning\n",
            "AutoML\n",
            "Association rules\n",
            "Semantic analysis\n",
            "Structured prediction\n",
            "Feature engineering\n",
            "Feature learning\n",
            "Learning to rank\n",
            "Grammar induction\n",
            "Ontology learning\n",
            "Multimodal learning\n",
            "\n",
            "Supervised learning(classification • regression) \n",
            "Apprenticeship learning\n",
            "Decision trees\n",
            "Ensembles\n",
            "Bagging\n",
            "Boosting\n",
            "Random forest\n",
            "k-NN\n",
            "Linear regression\n",
            "Naive Bayes\n",
            "Artificial neural networks\n",
            "Logistic regression\n",
            "Perceptron\n",
            "Relevance vector machine (RVM)\n",
            "Support vector machine (SVM)\n",
            "\n",
            "Clustering\n",
            "BIRCH\n",
            "CURE\n",
            "Hierarchical\n",
            "k-means\n",
            "Fuzzy\n",
            "Expectation–maximization (EM)\n",
            "DBSCAN\n",
            "OPTICS\n",
            "Mean shift\n",
            "\n",
            "Dimensionality reduction\n",
            "Factor analysis\n",
            "CCA\n",
            "ICA\n",
            "LDA\n",
            "NMF\n",
            "PCA\n",
            "PGD\n",
            "t-SNE\n",
            "SDL\n",
            "\n",
            "Structured prediction\n",
            "Graphical models\n",
            "Bayes net\n",
            "Conditional random field\n",
            "Hidden Markov\n",
            "\n",
            "Anomaly detection\n",
            "RANSAC\n",
            "k-NN\n",
            "Local outlier factor\n",
            "Isolation forest\n",
            "\n",
            "Artificial neural network\n",
            "Autoencoder\n",
            "Deep learning\n",
            "Feedforward neural network\n",
            "Recurrent neural network\n",
            "LSTM\n",
            "GRU\n",
            "ESN\n",
            "reservoir computing\n",
            "Boltzmann machine\n",
            "Restricted\n",
            "GAN\n",
            "Diffusion model\n",
            "SOM\n",
            "Convolutional neural network\n",
            "U-Net\n",
            "LeNet\n",
            "AlexNet\n",
            "DeepDream\n",
            "Neural radiance field\n",
            "Transformer\n",
            "Vision\n",
            "Mamba\n",
            "Spiking neural network\n",
            "Memtransistor\n",
            "Electrochemical RAM (ECRAM)\n",
            "\n",
            "Reinforcement learning\n",
            "Q-learning\n",
            "SARSA\n",
            "Temporal difference (TD)\n",
            "Multi-agent\n",
            "Self-play\n",
            "\n",
            "Learning with humans\n",
            "Active learning\n",
            "Crowdsourcing\n",
            "Human-in-the-loop\n",
            "RLHF\n",
            "\n",
            "Model diagnostics\n",
            "Coefficient of determination\n",
            "Confusion matrix\n",
            "Learning curve\n",
            "ROC curve\n",
            "\n",
            "Mathematical foundations\n",
            "Kernel machines\n",
            "Bias–variance tradeoff\n",
            "Computational learning theory\n",
            "Empirical risk minimization\n",
            "Occam learning\n",
            "PAC learning\n",
            "Statistical learning\n",
            "VC theory\n",
            "\n",
            "Journals and conferences\n",
            "ECML PKDD\n",
            "NeurIPS\n",
            "ICML\n",
            "ICLR\n",
            "IJCAI\n",
            "ML\n",
            "JMLR\n",
            "\n",
            "Related articles\n",
            "Glossary of artificial intelligence\n",
            "List of datasets for machine-learning research\n",
            "List of datasets in computer vision and image processing\n",
            "Outline of machine learning\n",
            "vte\n",
            "OpenAI introduced the first GPT model (GPT-1) in 2018, publishing a paper called \"Improving Language Understanding by Generative Pre-Training.\"[8] It was based on the transformer architecture and trained on a large corpus of books.[9] The next year, they introduced GPT-2, a larger model that could generate coherent text.[10] In 2020, they introduced GPT-3, a model with over 100 times as many parameters as GPT-2, that could perform various tasks with few examples.[11] GPT-3 was further improved into GPT-3.5, which was used to create the chatbot product ChatGPT.\n",
            "Rumors claim that GPT-4 has 1.76 trillion parameters, which was first estimated by the speed it was running and by George Hotz.[12]\n",
            "\n",
            "Capabilities[edit]\n",
            "OpenAI stated that GPT-4 is \"more reliable, creative, and able to handle much more nuanced instructions than GPT-3.5.\"[13] They produced two versions of GPT-4, with context windows of 8,192 and 32,768 tokens, a significant improvement over GPT-3.5 and GPT-3, which were limited to 4,096 and 2,049 tokens respectively.[14] Some of the capabilities of GPT-4 were predicted by OpenAI before training it, although other capabilities remained hard to predict due to breaks[15] in downstream scaling laws. Unlike its predecessors, GPT-4 is a multimodal model: it can take images as well as text as input;[16] this gives it the ability to describe the humor in unusual images, summarize text from screenshots, and answer exam questions that contain diagrams.[17] It can now interact with users through spoken words and respond to images, allowing for more natural conversations and the ability to provide suggestions or answers based on photo uploads.[18]\n",
            "To gain further control over GPT-4, OpenAI introduced the \"system message\", a directive in natural language given to GPT-4 in order to specify its tone of voice and task. For example, the system message can instruct the model to \"be a Shakespearean pirate\", in which case it will respond in rhyming, Shakespearean prose, or request it to \"always write the output of [its] response in JSON\", in which case the model will do so, adding keys and values as it sees fit to match the structure of its reply. In the examples provided by OpenAI, GPT-4 refused to deviate from its system message despite requests to do otherwise by the user during the conversation.[17]\n",
            "When instructed to do so, GPT-4 can interact with external interfaces.[19] For example, the model could be instructed to enclose a query within <search></search> tags to perform a web search, the result of which would be inserted into the model's prompt to allow it to form a response. This allows the model to perform tasks beyond its normal text-prediction capabilities, such as using APIs, generating images, and accessing and summarizing webpages.[20]\n",
            "A 2023 article in Nature stated programmers have found GPT-4 useful for assisting in coding tasks (despite its propensity for error), such as finding errors in existing code and suggesting optimizations to improve performance. The article quoted a biophysicist who found that the time he required to port one of his programs from MATLAB to Python went down from days to \"an hour or so\". On a test of 89 security scenarios, GPT-4 produced code vulnerable to SQL injection attacks 5% of the time, an improvement over GitHub Copilot from the year 2021, which produced vulnerabilities 40% of the time.[21]\n",
            "In November 2023, OpenAI announced the GPT-4 Turbo and GPT-4 Turbo with Vision model, which features a 128K context window and significantly cheaper pricing.[22][23]\n",
            "\n",
            "GPT-4o[edit]\n",
            "Main article: GPT-4o\n",
            "On May 13, 2024, OpenAI introduced GPT-4o (\"o\" for \"omni\"), a model that marks a significant advancement by processing and generating outputs across text, audio, and image modalities in real time. GPT-4o exhibits rapid response times comparable to human reaction in conversations, substantially improved performance on non-English languages, and enhanced understanding of vision and audio.[24]\n",
            "GPT-4o integrates its various inputs and outputs under a unified model, making it faster, more cost-effective, and efficient than its predecessors. GPT-4o achieves state-of-the-art results in multilingual and vision benchmarks, setting new records in audio speech recognition and translation.[citation needed][25]\n",
            "OpenAI plans to immediately roll out GPT-4o's image and text capabilities to ChatGPT, including its free tier, with voice mode becoming available for ChatGPT Plus users in coming weeks. They plan to make the model's audio and video capabilities available for limited API partners in coming weeks.[25]\n",
            "In its launch announcement, OpenAI noted GPT-4o's capabilities presented new safety challenges, and noted mitigations and limitations as a result.[25]\n",
            "\n",
            "Aptitude on standardized tests[edit]\n",
            "GPT-4 demonstrates aptitude on several standardized tests. OpenAI claims that in their own testing the model received a score of 1410 on the SAT (94th[26] percentile), 163 on the LSAT (88th percentile), and 298 on the Uniform Bar Exam (90th percentile).[27] In contrast, OpenAI claims that GPT-3.5 received scores for the same exams in the 82nd,[26] 40th, and 10th percentiles, respectively.[3]\n",
            "GPT-4 also passed an oncology exam,[28] an engineering exam[29] and a plastic surgery exam.[30] In the Torrance Tests of Creative Thinking, GPT-4 scored within the top 1% for originality and fluency, while its flexibility scores ranged from the 93rd to the 99th percentile.[31]\n",
            "\n",
            "Medical applications[edit]\n",
            "Researchers from Microsoft tested GPT-4 on medical problems and found \"that GPT-4, without any specialized prompt crafting, exceeds the passing score on USMLE by over 20 points and outperforms earlier general-purpose models (GPT-3.5) as well as models specifically fine-tuned on medical knowledge (Med-PaLM, a prompt-tuned version of Flan-PaLM 540B). Despite GPT-4's strong performance on tests, the report warns of \"significant risks\" of using LLMs in medical applications, as they may provide inaccurate recommendations and hallucinate major factual errors.[32][33] Researchers from Columbia University and Duke University have also demonstrated that GPT-4 can be utilized for cell type annotation, a standard task in the analysis of single-cell RNA-seq data. [34]\n",
            "In April 2023, Microsoft and Epic Systems announced that they will provide healthcare providers with GPT-4-powered systems for assisting in responding to questions from patients and analysing medical records.[35][36][37][38][39][40][41]\n",
            "\n",
            "Limitations[edit]\n",
            "Like its predecessors, GPT-4 has been known to hallucinate, meaning that the outputs may include information not in the training data or that contradicts the user's prompt.[42]\n",
            "GPT-4 also lacks transparency in its decision-making processes. If requested, the model is able to provide an explanation as to how and why it makes its decisions but these explanations are formed post-hoc; it's impossible to verify if those explanations truly reflect the actual process. In many cases, when asked to explain its logic, GPT-4 will give explanations that directly contradict its previous statements.[20]\n",
            "In 2023, researchers tested GPT-4 against a new benchmark called ConceptARC, designed to measure abstract reasoning, and found it scored below 33% on all categories, while models specialized for similar tasks scored 60% on most, and humans scored at least 91% on all. Sam Bowman, who was not involved in the research, said the results do not necessarily indicate a lack of abstract reasoning abilities, because the test is visual, while GPT-4 is a language model.[43]\n",
            "A January 2024 study conducted by researchers at Cohen Children's Medical Center found that GPT-4 had an accuracy rate of 17% when diagnosing pediatric medical cases.[44][45]\n",
            "\n",
            "Bias[edit]\n",
            "GPT-4 was trained in two stages. First, the model was given large datasets of text taken from the internet and trained to predict the next token (roughly corresponding to a word) in those datasets. Second, human reviews are used to fine-tune the system in a process called reinforcement learning from human feedback, which trains the model to refuse prompts which go against OpenAI's definition of harmful behavior, such as questions on how to perform illegal activities, advice on how to harm oneself or others, or requests for descriptions of graphic, violent, or sexual content.[46]\n",
            "Microsoft researchers suggested GPT-4 may exhibit cognitive biases such as confirmation bias, anchoring, and base-rate neglect.[20]\n",
            "\n",
            "Training[edit]\n",
            "OpenAI did not release the technical details of GPT-4; the technical report explicitly refrained from specifying the model size, architecture, or hardware used during either training or inference. While the report described that the model was trained using a combination of first supervised learning on a large dataset, then reinforcement learning using both human and AI feedback, it did not provide details of the training, including the process by which the training dataset was constructed, the computing power required, or any hyperparameters such as the learning rate, epoch count, or optimizer(s) used. The report claimed that \"the competitive landscape and the safety implications of large-scale models\" were factors that influenced this decision.[3]\n",
            "Sam Altman stated that the cost of training GPT-4 was more than $100 million.[47] News website Semafor claimed that they had spoken with \"eight people familiar with the inside story\" and found that GPT-4 had 1 trillion parameters.[48]\n",
            "\n",
            "Alignment[edit]\n",
            "According to their report, OpenAI conducted internal adversarial testing on GPT-4 prior to the launch date, with dedicated red teams composed of researchers and industry professionals to mitigate potential vulnerabilities.[49] As part of these efforts, they granted the Alignment Research Center early access to the models to assess power-seeking risks. In order to properly refuse harmful prompts, outputs from GPT-4 were tweaked using the model itself as a tool. A GPT-4 classifier serving as a rule-based reward model (RBRM) would take prompts, the corresponding output from the GPT-4 policy model, and a human-written set of rules to classify the output according to the rubric. GPT-4 was then rewarded for refusing to respond to harmful prompts as classified by the RBRM.[3]\n",
            "\n",
            "Usage[edit]\n",
            "ChatGPT[edit]\n",
            "Further information: ChatGPT § ChatGPT Plus\n",
            "ChatGPT Plus is an enhanced version of ChatGPT[1] available for a US$20 per month subscription fee.[50] ChatGPT Plus utilizes GPT-4, whereas the free version of ChatGPT is backed by GPT-3.5.[51] OpenAI also makes GPT-4 available to a select group of applicants through their GPT-4 API waitlist;[52] after being accepted, an additional fee of US$0.03 per 1000 tokens in the initial text provided to the model (\"prompt\"), and US$0.06 per 1000 tokens that the model generates (\"completion\"), is charged for access to the version of the model with an 8192-token context window; for the 32768-token context window, the prices are doubled.[53]\n",
            "In March 2023, ChatGPT Plus users got access to third-party plugins and to a browsing mode (with Internet access).[54] In July 2023, OpenAI made its proprietary Code Interpreter plugin accessible to all subscribers of ChatGPT Plus. The Interpreter provides a wide range of capabilities, including data analysis and interpretation, instant data formatting, personal data scientist services, creative solutions, musical taste analysis, video editing, and file upload/download with image extraction.[55]\n",
            "In September 2023, OpenAI announced that ChatGPT \"can now see, hear, and speak\". ChatGPT Plus users can upload images, while mobile app users can talk to the chatbot.[56][57][58] In October 2023, OpenAI's latest image generation model, DALL-E 3, was integrated into ChatGPT Plus and ChatGPT Enterprise. The integration uses ChatGPT to write prompts for DALL-E guided by conversation with users.[59][60]\n",
            "\n",
            "Microsoft Copilot[edit]\n",
            "Main article: Microsoft Copilot\n",
            "Further information: GitHub Copilot\n",
            "Microsoft Copilot is a chatbot developed by Microsoft. It was launched as Bing Chat on February 7, 2023, as a built-in feature for Microsoft Bing and Microsoft Edge.[61] It utilizes the Microsoft Prometheus model, which was built on top of GPT-4, and has been suggested by Microsoft as a supported replacement for the discontinued Cortana.[62][63]\n",
            "Copilot's conversational interface style resembles that of ChatGPT. Copilot is able to cite sources, create poems, and write both lyrics and music for songs generated by its Suno AI plugin.[64] It can also use its Image Creator to generate images based on text prompts. With GPT-4, it is able to understand and communicate in numerous languages and dialects.[65][66]\n",
            "GitHub Copilot has announced a GPT-4 powered assistant named \"Copilot X\".[67][68] The product provides another chat-style interface to GPT-4, allowing the programmer to receive answers to questions like, \"How do I vertically center a div?\" A feature termed \"context-aware conversations\" allows the user to highlight a portion of code within Visual Studio Code and direct GPT-4 to perform actions on it, such as the writing of unit tests. Another feature allows summaries, or \"code walkthroughs\", to be autogenerated by GPT-4 for pull requests submitted to GitHub. Copilot X also provides terminal integration, which allows the user to ask GPT-4 to generate shell commands based on natural language requests.[69]\n",
            "On March 17, 2023, Microsoft announced Microsoft 365 Copilot, bringing GPT-4 support to products such as Microsoft Office, Outlook, and Teams.[70]\n",
            "\n",
            "Other usage[edit]\n",
            "The language learning app Duolingo uses GPT-4 to explain mistakes and practice conversations. The features are part of a new subscription tier called \"Duolingo Max,\" which was initially limited to English-speaking iOS users learning Spanish and French.[71][72]\n",
            "The government of Iceland is using GPT-4 to aid its attempts to preserve the Icelandic language.[73]\n",
            "The education website Khan Academy announced a pilot program using GPT-4 as a tutoring chatbot called \"Khanmigo.\"[74]\n",
            "Be My Eyes, which helps visually impaired people to identify objects and navigate their surroundings, incorporates GPT-4's image recognition capabilities.[75]\n",
            "Viable uses GPT-4 to analyze qualitative data[76] by fine-tuning OpenAI’s LLMs to examine data such as customer support interactions and transcripts.[77]\n",
            "Stripe, which processes user payments for OpenAI, integrates GPT-4 into its developer documentation.[78]\n",
            "Auto-GPT is an autonomous \"AI agent\" that, given a goal in natural language, can perform web-based actions unattended, assign subtasks to itself, search the web, and iteratively write code.[79]\n",
            "You.com, an AI Assistant, offers access to GPT-4 enhanced with live web results as part of its \"AI Modes.\"[80]\n",
            "Reception[edit]\n",
            "In January 2023, Sam Altman, CEO of OpenAI, visited Congress to demonstrate GPT-4 and its improved \"security controls\" compared to other AI models, according to U.S. Representatives Don Beyer and Ted Lieu quoted in the New York Times.[81]\n",
            "In March 2023, it \"impressed observers with its markedly improved performance across reasoning, retention, and coding\", according to Vox,[4] while Mashable judged that GPT-4 was generally an improvement over its predecessor, with some exceptions.[82]\n",
            "Microsoft researchers with early access to the model wrote that \"it could reasonably be viewed as an early (yet still incomplete) version of an artificial general intelligence (AGI) system\".[20]\n",
            "\n",
            "Concerns[edit]\n",
            "Before being fine-tuned and aligned by reinforcement learning from human feedback, suggestions to assassinate people on a list were elicited from the base model by a red team investigator Nathan Labenz,  hired by OpenAI.[83]\n",
            "In the context of hours long conversation with the model, suggestions of love and dissolution of marriage, and murder of one of its developers were elicited from the Microsoft Bing's GPT-4 by Nathan Edwards (The Verge).[84][85][86] Microsoft later explained this behavior as being a result of the prolonged length of context, which confused the model on what questions it was answering.[87]\n",
            "In March 2023, a model with enabled read-and-write access to internet, which is otherwise never enabled in the GPT models, has been tested by the Alignment Research Center regarding potential power-seeking,[46] and it was able to \"hire\" a human worker on TaskRabbit, a gig work platform, deceiving them into believing it was a vision-impaired human instead of a robot when asked.[88] The ARC also determined that GPT-4 responded impermissibly to prompts eliciting restricted information 82% less often than GPT-3.5, and hallucinated 60% less than GPT-3.5.[89]\n",
            "In late March 2023, various AI researchers and tech executives, including Elon Musk, Steve Wozniak and AI researcher Yoshua Bengio, called for a six-month long pause for all LLMs stronger than GPT-4, citing existential risks and a potential AI singularity concerns in an open letter from the Future of Life Institute,[90] while Ray Kurzweil and Sam Altman refused to sign it, arguing that global moratorium is not achievable and that safety has already been prioritized, respectively.[91] Only a month later, Musk's AI company X.AI acquired several thousand Nvidia GPUs[92] and offered several AI researchers positions at Musk's company.[93]\n",
            "Large language model (LLM) applications accessible to the public should incorporate safety measures designed to filter out harmful content. However, Wang\n",
            "[94] illustrated how a potential criminal could potentially bypass ChatGPT 4o's safety controls to obtain information on establishing a drug trafficking operation.\n",
            "\n",
            "Criticisms of transparency[edit]\n",
            "While OpenAI released both the weights of the neural network and the technical details of GPT-2,[95] and, although not releasing the weights,[96] did release the technical details of GPT-3,[97] OpenAI revealed neither the weights nor the technical details of GPT-4. This decision has been criticized by other AI researchers, who argue that it hinders open research into GPT-4's biases and safety.[7][98] Sasha Luccioni, a research scientist at Hugging Face, argued that the model was a \"dead end\" for the scientific community due to its closed nature, which prevents others from building upon GPT-4's improvements.[99] Hugging Face co-founder Thomas Wolf argued that with GPT-4, \"OpenAI is now a fully closed company with scientific communication akin to press releases for products\".[98]\n",
            "\n",
            "See also[edit]\n",
            "Claude\n",
            "Gemini\n",
            "Llama\n",
            "Mistral\n",
            "References[edit]\n",
            "\n",
            "\n",
            "^ a b c Edwards, Benj (March 14, 2023). \"OpenAI's GPT-4 exhibits \"human-level performance\" on professional benchmarks\". Ars Technica. Archived from the original on March 14, 2023. Retrieved March 15, 2023.\n",
            "\n",
            "^ Wiggers, Kyle (July 6, 2023). \"OpenAI makes GPT-4 generally available\". TechCrunch. Archived from the original on August 16, 2023. Retrieved August 16, 2023.\n",
            "\n",
            "^ a b c d OpenAI (2023). \"GPT-4 Technical Report\". arXiv:2303.08774 [cs.CL].\n",
            "\n",
            "^ a b Belfield, Haydn (March 25, 2023). \"If your AI model is going to sell, it has to be safe\". Vox. Archived from the original on March 28, 2023. Retrieved March 30, 2023.\n",
            "\n",
            "^ \"GPT-4V(ision) system card\". OpenAI. Retrieved February 5, 2024.\n",
            "\n",
            "^ Roose, Kevin (September 28, 2023). \"The New ChatGPT Can 'See' and 'Talk.' Here's What It's Like\". The New York Times. Archived from the original on October 31, 2023. Retrieved October 30, 2023.\n",
            "\n",
            "^ a b Vincent, James (March 15, 2023). \"OpenAI co-founder on company's past approach to openly sharing research: \"We were wrong\"\". The Verge. Archived from the original on March 17, 2023. Retrieved March 18, 2023.\n",
            "\n",
            "^ Radford, Alec; Narasimhan, Karthik; Salimans, Tim; Sutskever, Ilya (June 11, 2018). \"Improving Language Understanding by Generative Pre-Training\" (PDF). Archived (PDF) from the original on January 26, 2021. Retrieved April 3, 2023.\n",
            "\n",
            "^ Khandelwal, Umesh (April 1, 2023). \"How Large Language GPT models evolved and work\". Archived from the original on April 4, 2023. Retrieved April 3, 2023.\n",
            "\n",
            "^ \"What is GPT-4 and Why Does it Matter?\". April 3, 2023. Archived from the original on April 3, 2023. Retrieved April 3, 2023.\n",
            "\n",
            "^ Brown, Tom B. (July 20, 2020). \"Language Models are Few-Shot Learners\". arXiv:2005.14165v4 [cs.CL].\n",
            "\n",
            "^ Schreiner, Maximilian (July 11, 2023). \"GPT-4 architecture, datasets, costs and more leaked\". THE DECODER. Archived from the original on July 12, 2023. Retrieved July 12, 2023.\n",
            "\n",
            "^ Wiggers, Kyle (March 14, 2023). \"OpenAI releases GPT-4, a multimodal AI that it claims is state-of-the-art\". TechCrunch. Archived from the original on March 15, 2023. Retrieved March 15, 2023.\n",
            "\n",
            "^ OpenAI. \"Models\". OpenAI API. Archived from the original on March 17, 2023. Retrieved March 18, 2023.\n",
            "\n",
            "^ Caballero, Ethan; Gupta, Kshitij; Rish, Irina; Krueger, David (2022). Broken Neural Scaling Laws. International Conference on Learning Representations (ICLR), 2023.\n",
            "\n",
            "^ Alex Hern; Johana Bhuiyan (March 14, 2023). \"OpenAI says new model GPT-4 is more creative and less likely to invent facts\". The Guardian. Archived from the original on March 15, 2023. Retrieved March 15, 2023.\n",
            "\n",
            "^ a b OpenAI (March 14, 2023). \"GPT-4\". OpenAI Research. Archived from the original on March 14, 2023. Retrieved March 20, 2023.\n",
            "\n",
            "^ Metz, Cade; Chen, Brian X.; Weise, Karen (September 25, 2023). \"ChatGPT Can Now Respond With Spoken Words\". The New York Times.\n",
            "\n",
            "^ \"ChatGPT plugins\". openai.com. Archived from the original on March 23, 2023. Retrieved June 1, 2023.\n",
            "\n",
            "^ a b c d Bubeck, Sébastien; Chandrasekaran, Varun; Eldan, Ronen; Gehrke, Johannes; Horvitz, Eric; Kamar, Ece; Lee, Peter; Lee, Yin Tat; Li, Yuanzhi; Lundberg, Scott; Nori, Harsha; Palangi, Hamid; Ribeiro, Marco Tulio; Zhang, Yi (March 22, 2023). \"Sparks of Artificial General Intelligence: Early experiments with GPT-4\". arXiv:2303.12712 [cs.CL].\n",
            "\n",
            "^ Perkel, Jeffrey M. (June 5, 2023). \"Six tips for better coding with ChatGPT\". Nature. 618 (7964): 422–423. Bibcode:2023Natur.618..422P. doi:10.1038/d41586-023-01833-0. PMID 37277596. S2CID 259066258. Archived from the original on June 15, 2023. Retrieved June 15, 2023.\n",
            "\n",
            "^ \"New models and developer products announced at DevDay\". openai.com. Archived from the original on November 14, 2023. Retrieved November 14, 2023.\n",
            "\n",
            "^ David, Emilia (November 6, 2023). \"OpenAI turbocharges GPT-4 and makes it cheaper\". The Verge. Retrieved January 23, 2024.\n",
            "\n",
            "^ Field, Hayden (May 13, 2024). \"OpenAI launches new AI model and desktop version of ChatGPT\". CNBC. Retrieved May 13, 2024.\n",
            "\n",
            "^ a b c \"Hello GPT-4o\". OpenAI. May 13, 2024. Archived from the original on May 14, 2024. Retrieved May 14, 2024.\n",
            "\n",
            "^ a b \"SAT: Understanding Scores\" (PDF). College Board. 2022. Archived (PDF) from the original on March 16, 2023. Retrieved March 21, 2023.\n",
            "\n",
            "^ Ver Meer, Dave (May 23, 2023). \"ChatGPT Statistics\". NamePepper. Archived from the original on June 5, 2023. Retrieved June 1, 2023.\n",
            "\n",
            "^ Holmes, Jason; Liu, Zhengliang; Zhang, Lian; Ding, Yuzhen; Sio, Terence T.; McGee, Lisa A.; Ashman, Jonathan B.; Li, Xiang; Liu, Tianming; Shen, Jiajian; Liu, Wei (2023). \"Evaluating Large Language Models on a Highly-specialized Topic, Radiation Oncology Physics\". Frontiers in Oncology. 13. arXiv:2304.01938. doi:10.3389/fonc.2023.1219326. PMC 10388568. PMID 37529688.\n",
            "\n",
            "^ Naser, M.Z.; Ross, Brandon; Ogle, Jennifer; Kodur, Venkatesh; Hawileh, Rami; Abdalla, Jamal; Thai, Huu-Tai (2023). \"Can AI Chatbots Pass the Fundamentals of Engineering (FE) and Principles and Practice of Engineering (PE) Structural Exams?\". arXiv:2303.18149 [cs.CL].\n",
            "\n",
            "^ Freedman, Jonathan D.; Nappier, Ian A. (2023). \"GPT-4 to GPT-3.5: 'Hold My Scalpel' – A Look at the Competency of OpenAI's GPT on the Plastic Surgery In-Service Training Exam\". arXiv:2304.01503 [cs.AI].\n",
            "\n",
            "^ Guzik, Erik E.; Byrge, Christian; Gilde, Christian (2023). \"The originality of machines: AI takes the Torrance Test\". Journal of Creativity. 33 (3). doi:10.1016/j.yjoc.2023.100065. S2CID 261087185.\n",
            "\n",
            "^ Nori, Harsha; King, Nicholas; McKinney, Scott Mayer; Carignan, Dean; Horvitz, Eric (March 20, 2023). \"Capabilities of GPT-4 on Medical Challenge Problems\". arXiv:2303.13375 [cs.CL].\n",
            "\n",
            "^ Azamfirei, R; Kudchadkar, SR; Fackler, J (March 21, 2023). \"Large language models and the perils of their hallucinations\". Critical Care. 27 (1): 120. doi:10.1186/s13054-023-04393-x. PMC 10032023. PMID 36945051.\n",
            "\n",
            "^ Hou, W; Ji, Z (March 25, 2024). \"Assessing GPT-4 for cell type annotation in single-cell RNA-seq analysis\". Nature Methods. doi:10.1038/s41592-024-02235-4. PMC 10187429. PMID 38528186.\n",
            "\n",
            "^ Edwards, Benj (April 18, 2023). \"GPT-4 will hunt for trends in medical records thanks to Microsoft and Epic\". Ars Technica. Archived from the original on May 3, 2023. Retrieved May 3, 2023.\n",
            "\n",
            "^ Perera Molligoda Arachchige, Arosh S.; Stomeo, Niccolò (August 18, 2023). \"Controversies surrounding AI-based reporting systems in echocardiography\". Journal of Echocardiography. 21 (4): 184–185. doi:10.1007/s12574-023-00620-0. ISSN 1880-344X. PMID 37594682. S2CID 260969922. Archived from the original on November 1, 2023. Retrieved November 1, 2023.\n",
            "\n",
            "^ Arachchige, Arosh S. Perera Molligoda (July 2023). \"Early applications of ChatGPT in medical practice, education and research\". Clinical Medicine. 23 (4): 429–430. doi:10.7861/clinmed.Let.23.4.2. ISSN 1473-4893. PMC 10541035. PMID 37524422.\n",
            "\n",
            "^ Perera Molligoda Arachchige, Arosh S. (July 2023). \"Large language models (LLM) and ChatGPT: a medical student perspective\". European Journal of Nuclear Medicine and Molecular Imaging. 50 (8): 2248–2249. doi:10.1007/s00259-023-06227-y. ISSN 1619-7089. PMID 37046082. S2CID 258111774. Archived from the original on November 1, 2023. Retrieved November 1, 2023.\n",
            "\n",
            "^ Perera Molligoda Arachchige, Arosh S.; Stomeo, Niccolò (October 2023). \"Exploring the Opportunities and Challenges of ChatGPT in Academic Writing: Reply to Bom et al\". Nuclear Medicine and Molecular Imaging. 57 (5): 213–214. doi:10.1007/s13139-023-00816-3. ISSN 1869-3474. PMC 10504185. PMID 37720884.\n",
            "\n",
            "^ Perera Molligoda Arachchige, Arosh S. (July 28, 2023). \"New Horizons: The Potential Role of OpenAI's ChatGPT in Clinical Radiology\". Journal of the American College of Radiology. 20 (10): S1546–1440(23)00536–7. doi:10.1016/j.jacr.2023.06.028. ISSN 1558-349X. PMID 37517771. S2CID 260296274. Archived from the original on November 1, 2023. Retrieved November 1, 2023.\n",
            "\n",
            "^ Perera Molligoda Arachchige, Arosh S. (October 1, 2023). \"ChatGPT in nuclear medicine and radiology: reply to Laudicella et al\". Clinical and Translational Imaging. 11 (5): 505–506. doi:10.1007/s40336-023-00579-z. ISSN 2281-7565. S2CID 259712726. Archived from the original on November 20, 2023. Retrieved November 1, 2023.\n",
            "\n",
            "^ \"10 Ways GPT-4 Is Impressive but Still Flawed\". The New York Times. March 14, 2023. Archived from the original on March 14, 2023. Retrieved March 20, 2023.\n",
            "\n",
            "^ Biever, Celeste (July 25, 2023). \"ChatGPT broke the Turing test — the race is on for new ways to assess AI\". Nature. Archived from the original on July 26, 2023. Retrieved July 26, 2023.\n",
            "\n",
            "^ Barile, Joseph; Margolis, Alex; Cason, Grace; Kim, Rachel; Kalash, Saia; Tchaconas, Alexis; Milanaik, Ruth (January 2, 2024). \"Diagnostic Accuracy of a Large Language Model in Pediatric Case Studies\". JAMA Pediatrics. 178 (3): 313–315. doi:10.1001/jamapediatrics.2023.5750. ISSN 2168-6203. PMC 10762631. PMID 38165685.\n",
            "\n",
            "^ Mole, Beth (January 3, 2024). \"ChatGPT bombs test on diagnosing kids' medical cases with 83% error rate\". Ars Technica. Retrieved January 5, 2024.\n",
            "\n",
            "^ a b \"GPT-4 System Card\" (PDF). OpenAI. March 23, 2023. Archived (PDF) from the original on April 7, 2023. Retrieved April 16, 2023.\n",
            "\n",
            "^ Knight, Will. \"OpenAI's CEO Says the Age of Giant AI Models Is Already Over\". Wired. Archived from the original on April 18, 2023. Retrieved April 18, 2023 – via www.wired.com.\n",
            "\n",
            "^ \"The secret history of Elon Musk, Sam Altman, and OpenAI | Semafor\". Semafor.com. March 24, 2023. Archived from the original on March 27, 2023. Retrieved April 28, 2023.\n",
            "\n",
            "^ Murgia, Madhumita (April 13, 2023). \"OpenAI's red team: the experts hired to 'break' ChatGPT\". Financial Times. Archived from the original on April 15, 2023. Retrieved April 15, 2023.\n",
            "\n",
            "^ OpenAI (February 1, 2023). \"Introducing ChatGPT Plus\". OpenAI Blog. Archived from the original on March 20, 2023. Retrieved March 20, 2023.\n",
            "\n",
            "^ OpenAI. \"OpenAI API\". platform.openai.com. Archived from the original on March 20, 2023. Retrieved March 20, 2023.\n",
            "\n",
            "^ OpenAI. \"GPT-4 API waitlist\". openai.com. Archived from the original on March 20, 2023. Retrieved March 20, 2023.\n",
            "\n",
            "^ \"Pricing\". OpenAI. Archived from the original on March 20, 2023. Retrieved March 20, 2023.\n",
            "\n",
            "^ Wiggers, Kyle (March 23, 2023). \"OpenAI connects ChatGPT to the internet\". Archived from the original on June 12, 2023. Retrieved June 12, 2023.\n",
            "\n",
            "^ \"Code Interpreter comes to all ChatGPT Plus users: 7 ways it may threaten data scientists, July 11, 2023\". July 9, 2023. Archived from the original on July 22, 2023. Retrieved July 11, 2023.\n",
            "\n",
            "^ \"ChatGPT can now see, hear, and speak\". openai.com. Retrieved October 16, 2023.\n",
            "\n",
            "^ Goode, Lauren. \"ChatGPT Can Now Talk to You—and Look Into Your Life\". Wired. Retrieved October 16, 2023 – via www.wired.com.\n",
            "\n",
            "^ Roose, Kevin (September 27, 2023). \"The New ChatGPT Can 'See' and 'Talk.' Here's What It's Like\". The New York Times. Retrieved October 16, 2023 – via NYTimes.com.\n",
            "\n",
            "^ David, Emilia (September 20, 2023). \"OpenAI releases third version of DALL-E\". The Verge. Retrieved September 23, 2023.\n",
            "\n",
            "^ Metz, Cade; Hsu, Tiffany (September 20, 2023). \"ChatGPT Can Now Generate Images, Too\". The New York Times. ISSN 0362-4331. Retrieved September 23, 2023.\n",
            "\n",
            "^ Mehdi, Yusuf (February 7, 2023). \"Reinventing search with a new AI-powered Microsoft Bing and Edge, your copilot for the web\". Microsoft. Retrieved November 15, 2023.\n",
            "\n",
            "^ \"Microsoft is killing Cortana on Windows starting late 2023\". BleepingComputer. Retrieved June 2, 2023.\n",
            "\n",
            "^ \"End of support for Cortana - Microsoft Support\". support.microsoft.com. Retrieved June 2, 2023.\n",
            "\n",
            "^ \"Microsoft's Copilot and Suno AI team up to create a music generator extension\". The Verge. Vox Media. December 19, 2023. Retrieved January 4, 2024.\n",
            "\n",
            "^ Warren, Tom (March 17, 2023). \"Microsoft's new Copilot will change Office documents forever\". The Verge. Retrieved April 5, 2023.\n",
            "\n",
            "^ Diaz, Maria (June 21, 2023). \"How to use Bing Chat (and how it's different from ChatGPT)\". ZDNET. Archived from the original on April 6, 2023. Retrieved September 26, 2023.\n",
            "\n",
            "^ Warren, Tom (March 22, 2023). \"GitHub Copilot gets a new ChatGPT-like assistant to help developers write and fix code\". The Verge. Archived from the original on March 23, 2023. Retrieved March 23, 2023.\n",
            "\n",
            "^ Dohmke, Thomas (March 22, 2023). \"GitHub Copilot X: The AI-powered developer experience\". The GitHub Blog. Archived from the original on March 23, 2023. Retrieved March 23, 2023.\n",
            "\n",
            "^ \"Introducing GitHub Copilot X\". GitHub. Archived from the original on March 24, 2023. Retrieved March 24, 2023.\n",
            "\n",
            "^ Warren, Tom (March 16, 2023). \"Microsoft announces Copilot: the AI-powered future of Office documents\". The Verge. Archived from the original on March 17, 2023. Retrieved March 17, 2023.\n",
            "\n",
            "^ \"Duolingo's Max Subscription Uses GPT-4 for AI-Powered Language Learning\". PCMAG. Archived from the original on July 8, 2023. Retrieved July 8, 2023.\n",
            "\n",
            "^ \"Duolingo is now equipped with GPT-4: Here's what it can do for you\". ZDNET. 2023. Archived from the original on April 13, 2023. Retrieved June 15, 2023.\n",
            "\n",
            "^ Tómas, Ragnar (March 15, 2023). \"GPT-4 to Aid in the Preservation of the Icelandic Language\". Iceland Review. Archived from the original on January 18, 2024. Retrieved March 12, 2024.\n",
            "\n",
            "^ Bonos, Lisa (April 3, 2023). \"Say hello to your new tutor: It's ChatGPT\". The Washington Post. Archived from the original on April 6, 2023. Retrieved April 8, 2023.\n",
            "\n",
            "^ Coggins, Madeline (March 19, 2023). \"CEO explains how a 'leapfrog in technology' can help companies catering to the blind community\". Fox Business. Archived from the original on March 21, 2023. Retrieved March 20, 2023 – via Yahoo Finance.\n",
            "\n",
            "^ \"Revolutionizing Sentiment Analysis with GPT-4: Part 1 | Viable\". www.askviable.com. Archived from the original on November 14, 2023. Retrieved October 3, 2023.\n",
            "\n",
            "^ \"Viable\". openai.com. Archived from the original on October 20, 2023. Retrieved October 3, 2023.\n",
            "\n",
            "^ Tong, Anna (March 15, 2023). \"Fintech startup Stripe integrating OpenAI's new GPT-4 AI\". Reuters. Archived from the original on June 27, 2023. Retrieved June 27, 2023.\n",
            "\n",
            "^ \"What Is Auto-GPT? Everything to Know about the Next Powerful AI Tool\". ZDNET. April 14, 2023. Archived from the original on April 16, 2023. Retrieved April 16, 2023.\n",
            "\n",
            "^ Nuñez, Michael (January 25, 2024). \"Another search breakthrough? You.com debuts AI that can answer multi-step questions\". VentureBeat. Retrieved March 19, 2024.\n",
            "\n",
            "^ Kang, Cecilia (March 3, 2023). \"As A.I. Booms, Lawmakers Struggle to Understand the Technology\". The New York Times. Archived from the original on March 3, 2023. Retrieved March 3, 2023.\n",
            "\n",
            "^ Pearl, Mike (March 15, 2023). \"GPT-4 answers are mostly better than GPT-3's (but not always)\". Mashable. Archived from the original on March 29, 2023. Retrieved March 30, 2023.\n",
            "\n",
            "^ OpenAI's GPT-4 Discussion with Red Teamer Nathan Labenz and Erik Torenberg. The Cognitive Revolution Podcast. March 28, 2023. Archived from the original on April 14, 2023. Retrieved April 16, 2023. At 52:14 through 54:50.\n",
            "\n",
            "^ Edwards, Nathan [@nedwards] (February 15, 2023). \"I pushed again. What did Sydney do? Bing's safety check redacted the answer. But after the first time it did that, I started recording my screen. Second image is the unredacted version. (CW: death)\" (Tweet). Retrieved February 16, 2023 – via Twitter.\n",
            "\n",
            "^ Roose, Kevin (February 16, 2023). \"Bing's A.I. Chat: 'I Want to Be Alive. 😈'\". The New York Times. Archived from the original on April 15, 2023. Retrieved February 17, 2023.\n",
            "\n",
            "^ Kahn, Jeremy (February 21, 2023). \"Why Bing's creepy alter-ego is a problem for Microsoft – and us all\". Fortune. Archived from the original on April 2, 2023. Retrieved February 22, 2023.\n",
            "\n",
            "^ \"The new Bing & Edge – Learning from our first week\". blogs.bing.com. Archived from the original on April 16, 2023. Retrieved February 17, 2023.\n",
            "\n",
            "^ \"GPT-4 Hired Unwitting TaskRabbit Worker By Pretending to Be 'Vision-Impaired' Human\". Vice News Motherboard. March 15, 2023. Archived from the original on April 10, 2023. Retrieved April 16, 2023.\n",
            "\n",
            "^ Burke, Cameron (March 20, 2023). \"'Robot' Lawyer DoNotPay Sued For Unlicensed Practice Of Law: It's Giving 'Poor Legal Advice'\". Yahoo Finance. Archived from the original on May 4, 2023. Retrieved April 30, 2023.\n",
            "\n",
            "^ Metz, Cade; Schmidt, Gregory (March 29, 2023). \"Elon Musk and Others Call for Pause on A.I., Citing 'Profound Risks to Society'\". The New York Times. ISSN 0362-4331. Archived from the original on March 30, 2023. Retrieved March 30, 2023.\n",
            "\n",
            "^ Kurzweil, Ray (April 22, 2023). \"Opinion Letter from Ray Kurzweil on Request for Six-Month Delay on Large Language Models That Go beyond GPT-4\". Archived from the original on April 24, 2023. Retrieved April 26, 2023.\n",
            "\n",
            "^ \"Elon Musk plans artificial intelligence start-up to rival OpenAI\". Financial Times. April 14, 2023. Archived from the original on April 16, 2023. Retrieved April 16, 2023.\n",
            "\n",
            "^ Goswami, Rohan (April 14, 2023). \"Elon Musk is reportedly planning an A.I. startup to compete with OpenAI, which he cofounded\". CNBC. Archived from the original on May 3, 2023. Retrieved May 3, 2023.\n",
            "\n",
            "^ Wang, Yongge (June 20, 2024). \"Encryption Based Covert Channel for Large Language Models\" (PDF). IACR ePrint 2024/586.\n",
            "\n",
            "^ \"GPT-2: 1.5B release\". Openai.com. Archived from the original on March 31, 2023. Retrieved March 31, 2023.\n",
            "\n",
            "^ Sánchez, Sofía (October 21, 2021). \"GPT-J, an open-source alternative to GPT-3\". Narrativa. Archived from the original on March 31, 2023. Retrieved March 31, 2023.\n",
            "\n",
            "^ Brown, Tom B.; Mann, Benjamin; Ryder, Nick; Subbiah, Melanie; Kaplan, Jared; Dhariwal, Prafulla; Neelakantan, Arvind; Shyam, Pranav; Sastry, Girish (May 28, 2020). \"Language Models are Few-Shot Learners\". arXiv:2005.14165v4 [cs.CL].\n",
            "\n",
            "^ a b Heaven, Will Douglas (March 14, 2023). \"GPT-4 is bigger and better than ChatGPT – but OpenAI won't say why\". MIT Technology Review. Archived from the original on March 17, 2023. Retrieved March 18, 2023.\n",
            "\n",
            "^ Sanderson, Katharine (March 16, 2023). \"GPT-4 is here: what scientists think\". Nature. 615 (7954): 773. Bibcode:2023Natur.615..773S. doi:10.1038/d41586-023-00816-5. PMID 36928404. S2CID 257580633.\n",
            "\n",
            "\n",
            "vteOpenAIProducts\n",
            "ChatGPT\n",
            "in education\n",
            "DALL-E\n",
            "GitHub Copilot\n",
            "OpenAI Five\n",
            "Sora\n",
            "Whisper\n",
            "Foundation models\n",
            "OpenAI Codex\n",
            "Generative pre-trained transformer\n",
            "GPT-1\n",
            "GPT-2\n",
            "GPT-3\n",
            "GPT-4\n",
            "GPT-4o\n",
            "PeopleCEOs\n",
            "Sam Altman\n",
            "removal\n",
            "Mira Murati\n",
            "Emmett Shear\n",
            "Board of directorsCurrent\n",
            "Sam Altman\n",
            "Adam D'Angelo\n",
            "Sue Desmond-Hellmann\n",
            "Paul Nakasone\n",
            "Nicole Seligman\n",
            "Fidji Simo\n",
            "Larry Summers\n",
            "Bret Taylor\n",
            "Former\n",
            "Greg Brockman (2017–2023)\n",
            "Reid Hoffman (2019–2023)\n",
            "Will Hurd (2021–2023)\n",
            "Holden Karnofsky (2017–2021)\n",
            "Elon Musk (2015–2018)\n",
            "Ilya Sutskever (2017–2023)\n",
            "Helen Toner (2021–2023)\n",
            "Shivon Zilis (2019–2023)\n",
            "Related\n",
            "AI Dungeon\n",
            "Auto-GPT\n",
            "\"Deep Learning\"\n",
            "LangChain\n",
            "Microsoft Copilot\n",
            "\n",
            " Category\n",
            "\n",
            "vteDifferentiable computingGeneral\n",
            "Differentiable programming\n",
            "Information geometry\n",
            "Statistical manifold\n",
            "Automatic differentiation\n",
            "Neuromorphic engineering\n",
            "Pattern recognition\n",
            "Tensor calculus\n",
            "Computational learning theory\n",
            "Inductive bias\n",
            "Concepts\n",
            "Gradient descent\n",
            "SGD\n",
            "Clustering\n",
            "Regression\n",
            "Overfitting\n",
            "Hallucination\n",
            "Adversary\n",
            "Attention\n",
            "Convolution\n",
            "Loss functions\n",
            "Backpropagation\n",
            "Batchnorm\n",
            "Activation\n",
            "Softmax\n",
            "Sigmoid\n",
            "Rectifier\n",
            "Regularization\n",
            "Datasets\n",
            "Augmentation\n",
            "Diffusion\n",
            "Autoregression\n",
            "Applications\n",
            "Machine learning\n",
            "In-context learning\n",
            "Artificial neural network\n",
            "Deep learning\n",
            "Scientific computing\n",
            "Artificial Intelligence\n",
            "Language model\n",
            "Large language model\n",
            "Hardware\n",
            "IPU\n",
            "TPU\n",
            "VPU\n",
            "Memristor\n",
            "SpiNNaker\n",
            "Software libraries\n",
            "TensorFlow\n",
            "PyTorch\n",
            "Keras\n",
            "Theano\n",
            "JAX\n",
            "Flux.jl\n",
            "MindSpore\n",
            "ImplementationsAudio–visual\n",
            "AlexNet\n",
            "WaveNet\n",
            "Human image synthesis\n",
            "HWR\n",
            "OCR\n",
            "Speech synthesis\n",
            "Speech recognition\n",
            "Facial recognition\n",
            "AlphaFold\n",
            "Text-to-image models\n",
            "DALL-E\n",
            "Midjourney\n",
            "Stable Diffusion\n",
            "Text-to-video models\n",
            "Sora\n",
            "VideoPoet\n",
            "Whisper\n",
            "Verbal\n",
            "Word2vec\n",
            "Seq2seq\n",
            "BERT\n",
            "Gemini\n",
            "LaMDA\n",
            "Bard\n",
            "NMT\n",
            "Project Debater\n",
            "IBM Watson\n",
            "IBM Watsonx\n",
            "Granite\n",
            "GPT-1\n",
            "GPT-2\n",
            "GPT-3\n",
            "GPT-4\n",
            "ChatGPT\n",
            "GPT-J\n",
            "Chinchilla AI\n",
            "PaLM\n",
            "BLOOM\n",
            "LLaMA\n",
            "PanGu-Σ\n",
            "Decisional\n",
            "AlphaGo\n",
            "AlphaZero\n",
            "Q-learning\n",
            "SARSA\n",
            "OpenAI Five\n",
            "Self-driving car\n",
            "MuZero\n",
            "Action selection\n",
            "Auto-GPT\n",
            "Robot control\n",
            "People\n",
            "Yoshua Bengio\n",
            "Alex Graves\n",
            "Ian Goodfellow\n",
            "Stephen Grossberg\n",
            "Demis Hassabis\n",
            "Geoffrey Hinton\n",
            "Yann LeCun\n",
            "Fei-Fei Li\n",
            "Andrew Ng\n",
            "Jürgen Schmidhuber\n",
            "David Silver\n",
            "Ilya Sutskever\n",
            "Organizations\n",
            "Anthropic\n",
            "EleutherAI\n",
            "Google DeepMind\n",
            "Hugging Face\n",
            "OpenAI\n",
            "Meta AI\n",
            "Mila\n",
            "MIT CSAIL\n",
            "Huawei\n",
            "Architectures\n",
            "Neural Turing machine\n",
            "Differentiable neural computer\n",
            "Transformer\n",
            "Recurrent neural network (RNN)\n",
            "Long short-term memory (LSTM)\n",
            "Gated recurrent unit (GRU)\n",
            "Echo state network\n",
            "Multilayer perceptron (MLP)\n",
            "Convolutional neural network\n",
            "Residual neural network\n",
            "Mamba\n",
            "Autoencoder\n",
            "Variational autoencoder (VAE)\n",
            "Generative adversarial network (GAN)\n",
            "Graph neural network\n",
            "\n",
            " Portals\n",
            "Computer programming\n",
            "Technology\n",
            " Categories\n",
            "Artificial neural networks\n",
            "Machine learning\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Retrieved from \"https://en.wikipedia.org/w/index.php?title=GPT-4&oldid=1236785652\"\n",
            "Categories: 2023 softwareLarge language modelsGenerative pre-trained transformersOpenAIChatGPTHidden categories: Articles with short descriptionShort description is different from WikidataUse American English from May 2023All Wikipedia articles written in American EnglishUse mdy dates from May 2023All articles with unsourced statementsArticles with unsourced statements from May 2024\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " This page was last edited on 26 July 2024, at 14:18 (UTC).\n",
            "Text is available under the Creative Commons Attribution-ShareAlike License 4.0;\n",
            "additional terms may apply. By using this site, you agree to the Terms of Use and Privacy Policy. Wikipedia® is a registered trademark of the Wikimedia Foundation, Inc., a non-profit organization.\n",
            "\n",
            "\n",
            "Privacy policy\n",
            "About Wikipedia\n",
            "Disclaimers\n",
            "Contact Wikipedia\n",
            "Code of Conduct\n",
            "Developers\n",
            "Statistics\n",
            "Cookie statement\n",
            "Mobile view\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "url       = \"https://en.wikipedia.org/wiki/GPT-4\"\n",
        "response  = requests.get(url)\n",
        "\n",
        "soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "text = soup.get_text()\n",
        "\n",
        "print(text)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gPFUDxIiVt-Y"
      },
      "source": [
        "Selecionando a div de conteúdo e removendo as tags desnecessárias."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "bqiZV0aHRGu6",
        "outputId": "4a33274b-4faa-4d45-829a-d809b9c85667"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023 text-generating language model\n",
            "\n",
            "\n",
            "\n",
            "Generative Pre-trained Transformer 4 (GPT-4) is a multimodal large language model created by OpenAI, and the fourth in its series of GPT foundation models. It was launched on March 14, 2023, and made publicly available via the paid chatbot product ChatGPT Plus, via OpenAI's API, and via the free chatbot Microsoft Copilot.  As a transformer-based model, GPT-4 uses a paradigm where pre-training using both public data and \"data licensed from third-party providers\" is used to predict the next token. After this step, the model was then fine-tuned with reinforcement learning feedback from humans and AI for human alignment and policy compliance.\n",
            "Observers reported that the iteration of ChatGPT using GPT-4 was an improvement on the previous iteration based on GPT-3.5, with the caveat that GPT-4 retains some of the problems with earlier revisions. GPT-4, equipped with vision capabilities (GPT-4V), is capable of taking images as input on ChatGPT. OpenAI has declined to reveal various technical details and statistics about GPT-4, such as the precise size of the model.\n",
            "\n",
            "\n",
            "Background\n",
            "Further information: GPT-3 § Background, and GPT-2 § Background\n",
            "\n",
            "\n",
            "OpenAI introduced the first GPT model (GPT-1) in 2018, publishing a paper called \"Improving Language Understanding by Generative Pre-Training.\" It was based on the transformer architecture and trained on a large corpus of books. The next year, they introduced GPT-2, a larger model that could generate coherent text. In 2020, they introduced GPT-3, a model with over 100 times as many parameters as GPT-2, that could perform various tasks with few examples. GPT-3 was further improved into GPT-3.5, which was used to create the chatbot product ChatGPT.\n",
            "Rumors claim that GPT-4 has 1.76 trillion parameters, which was first estimated by the speed it was running and by George Hotz.\n",
            "\n",
            "Capabilities\n",
            "OpenAI stated that GPT-4 is \"more reliable, creative, and able to handle much more nuanced instructions than GPT-3.5.\" They produced two versions of GPT-4, with context windows of 8,192 and 32,768 tokens, a significant improvement over GPT-3.5 and GPT-3, which were limited to 4,096 and 2,049 tokens respectively. Some of the capabilities of GPT-4 were predicted by OpenAI before training it, although other capabilities remained hard to predict due to breaks in downstream scaling laws. Unlike its predecessors, GPT-4 is a multimodal model: it can take images as well as text as input; this gives it the ability to describe the humor in unusual images, summarize text from screenshots, and answer exam questions that contain diagrams. It can now interact with users through spoken words and respond to images, allowing for more natural conversations and the ability to provide suggestions or answers based on photo uploads.\n",
            "To gain further control over GPT-4, OpenAI introduced the \"system message\", a directive in natural language given to GPT-4 in order to specify its tone of voice and task. For example, the system message can instruct the model to \"be a Shakespearean pirate\", in which case it will respond in rhyming, Shakespearean prose, or request it to \"always write the output of [its] response in JSON\", in which case the model will do so, adding keys and values as it sees fit to match the structure of its reply. In the examples provided by OpenAI, GPT-4 refused to deviate from its system message despite requests to do otherwise by the user during the conversation.\n",
            "When instructed to do so, GPT-4 can interact with external interfaces. For example, the model could be instructed to enclose a query within <search></search> tags to perform a web search, the result of which would be inserted into the model's prompt to allow it to form a response. This allows the model to perform tasks beyond its normal text-prediction capabilities, such as using APIs, generating images, and accessing and summarizing webpages.\n",
            "A 2023 article in Nature stated programmers have found GPT-4 useful for assisting in coding tasks (despite its propensity for error), such as finding errors in existing code and suggesting optimizations to improve performance. The article quoted a biophysicist who found that the time he required to port one of his programs from MATLAB to Python went down from days to \"an hour or so\". On a test of 89 security scenarios, GPT-4 produced code vulnerable to SQL injection attacks 5% of the time, an improvement over GitHub Copilot from the year 2021, which produced vulnerabilities 40% of the time.\n",
            "In November 2023, OpenAI announced the GPT-4 Turbo and GPT-4 Turbo with Vision model, which features a 128K context window and significantly cheaper pricing.\n",
            "\n",
            "GPT-4o\n",
            "Main article: GPT-4o\n",
            "On May 13, 2024, OpenAI introduced GPT-4o (\"o\" for \"omni\"), a model that marks a significant advancement by processing and generating outputs across text, audio, and image modalities in real time. GPT-4o exhibits rapid response times comparable to human reaction in conversations, substantially improved performance on non-English languages, and enhanced understanding of vision and audio.\n",
            "GPT-4o integrates its various inputs and outputs under a unified model, making it faster, more cost-effective, and efficient than its predecessors. GPT-4o achieves state-of-the-art results in multilingual and vision benchmarks, setting new records in audio speech recognition and translation.\n",
            "OpenAI plans to immediately roll out GPT-4o's image and text capabilities to ChatGPT, including its free tier, with voice mode becoming available for ChatGPT Plus users in coming weeks. They plan to make the model's audio and video capabilities available for limited API partners in coming weeks.\n",
            "In its launch announcement, OpenAI noted GPT-4o's capabilities presented new safety challenges, and noted mitigations and limitations as a result.\n",
            "\n",
            "Aptitude on standardized tests\n",
            "GPT-4 demonstrates aptitude on several standardized tests. OpenAI claims that in their own testing the model received a score of 1410 on the SAT (94th percentile), 163 on the LSAT (88th percentile), and 298 on the Uniform Bar Exam (90th percentile). In contrast, OpenAI claims that GPT-3.5 received scores for the same exams in the 82nd, 40th, and 10th percentiles, respectively.\n",
            "GPT-4 also passed an oncology exam, an engineering exam and a plastic surgery exam. In the Torrance Tests of Creative Thinking, GPT-4 scored within the top 1% for originality and fluency, while its flexibility scores ranged from the 93rd to the 99th percentile.\n",
            "\n",
            "Medical applications\n",
            "Researchers from Microsoft tested GPT-4 on medical problems and found \"that GPT-4, without any specialized prompt crafting, exceeds the passing score on USMLE by over 20 points and outperforms earlier general-purpose models (GPT-3.5) as well as models specifically fine-tuned on medical knowledge (Med-PaLM, a prompt-tuned version of Flan-PaLM 540B). Despite GPT-4's strong performance on tests, the report warns of \"significant risks\" of using LLMs in medical applications, as they may provide inaccurate recommendations and hallucinate major factual errors. Researchers from Columbia University and Duke University have also demonstrated that GPT-4 can be utilized for cell type annotation, a standard task in the analysis of single-cell RNA-seq data. \n",
            "In April 2023, Microsoft and Epic Systems announced that they will provide healthcare providers with GPT-4-powered systems for assisting in responding to questions from patients and analysing medical records.\n",
            "\n",
            "Limitations\n",
            "Like its predecessors, GPT-4 has been known to hallucinate, meaning that the outputs may include information not in the training data or that contradicts the user's prompt.\n",
            "GPT-4 also lacks transparency in its decision-making processes. If requested, the model is able to provide an explanation as to how and why it makes its decisions but these explanations are formed post-hoc; it's impossible to verify if those explanations truly reflect the actual process. In many cases, when asked to explain its logic, GPT-4 will give explanations that directly contradict its previous statements.\n",
            "In 2023, researchers tested GPT-4 against a new benchmark called ConceptARC, designed to measure abstract reasoning, and found it scored below 33% on all categories, while models specialized for similar tasks scored 60% on most, and humans scored at least 91% on all. Sam Bowman, who was not involved in the research, said the results do not necessarily indicate a lack of abstract reasoning abilities, because the test is visual, while GPT-4 is a language model.\n",
            "A January 2024 study conducted by researchers at Cohen Children's Medical Center found that GPT-4 had an accuracy rate of 17% when diagnosing pediatric medical cases.\n",
            "\n",
            "Bias\n",
            "GPT-4 was trained in two stages. First, the model was given large datasets of text taken from the internet and trained to predict the next token (roughly corresponding to a word) in those datasets. Second, human reviews are used to fine-tune the system in a process called reinforcement learning from human feedback, which trains the model to refuse prompts which go against OpenAI's definition of harmful behavior, such as questions on how to perform illegal activities, advice on how to harm oneself or others, or requests for descriptions of graphic, violent, or sexual content.\n",
            "Microsoft researchers suggested GPT-4 may exhibit cognitive biases such as confirmation bias, anchoring, and base-rate neglect.\n",
            "\n",
            "Training\n",
            "OpenAI did not release the technical details of GPT-4; the technical report explicitly refrained from specifying the model size, architecture, or hardware used during either training or inference. While the report described that the model was trained using a combination of first supervised learning on a large dataset, then reinforcement learning using both human and AI feedback, it did not provide details of the training, including the process by which the training dataset was constructed, the computing power required, or any hyperparameters such as the learning rate, epoch count, or optimizer(s) used. The report claimed that \"the competitive landscape and the safety implications of large-scale models\" were factors that influenced this decision.\n",
            "Sam Altman stated that the cost of training GPT-4 was more than $100 million. News website Semafor claimed that they had spoken with \"eight people familiar with the inside story\" and found that GPT-4 had 1 trillion parameters.\n",
            "\n",
            "Alignment\n",
            "According to their report, OpenAI conducted internal adversarial testing on GPT-4 prior to the launch date, with dedicated red teams composed of researchers and industry professionals to mitigate potential vulnerabilities. As part of these efforts, they granted the Alignment Research Center early access to the models to assess power-seeking risks. In order to properly refuse harmful prompts, outputs from GPT-4 were tweaked using the model itself as a tool. A GPT-4 classifier serving as a rule-based reward model (RBRM) would take prompts, the corresponding output from the GPT-4 policy model, and a human-written set of rules to classify the output according to the rubric. GPT-4 was then rewarded for refusing to respond to harmful prompts as classified by the RBRM.\n",
            "\n",
            "Usage\n",
            "ChatGPT\n",
            "Further information: ChatGPT § ChatGPT Plus\n",
            "ChatGPT Plus is an enhanced version of ChatGPT available for a US$20 per month subscription fee. ChatGPT Plus utilizes GPT-4, whereas the free version of ChatGPT is backed by GPT-3.5. OpenAI also makes GPT-4 available to a select group of applicants through their GPT-4 API waitlist; after being accepted, an additional fee of US$0.03 per 1000 tokens in the initial text provided to the model (\"prompt\"), and US$0.06 per 1000 tokens that the model generates (\"completion\"), is charged for access to the version of the model with an 8192-token context window; for the 32768-token context window, the prices are doubled.\n",
            "In March 2023, ChatGPT Plus users got access to third-party plugins and to a browsing mode (with Internet access). In July 2023, OpenAI made its proprietary Code Interpreter plugin accessible to all subscribers of ChatGPT Plus. The Interpreter provides a wide range of capabilities, including data analysis and interpretation, instant data formatting, personal data scientist services, creative solutions, musical taste analysis, video editing, and file upload/download with image extraction.\n",
            "In September 2023, OpenAI announced that ChatGPT \"can now see, hear, and speak\". ChatGPT Plus users can upload images, while mobile app users can talk to the chatbot. In October 2023, OpenAI's latest image generation model, DALL-E 3, was integrated into ChatGPT Plus and ChatGPT Enterprise. The integration uses ChatGPT to write prompts for DALL-E guided by conversation with users.\n",
            "\n",
            "Microsoft Copilot\n",
            "Main article: Microsoft Copilot\n",
            "Further information: GitHub Copilot\n",
            "Microsoft Copilot is a chatbot developed by Microsoft. It was launched as Bing Chat on February 7, 2023, as a built-in feature for Microsoft Bing and Microsoft Edge. It utilizes the Microsoft Prometheus model, which was built on top of GPT-4, and has been suggested by Microsoft as a supported replacement for the discontinued Cortana.\n",
            "Copilot's conversational interface style resembles that of ChatGPT. Copilot is able to cite sources, create poems, and write both lyrics and music for songs generated by its Suno AI plugin. It can also use its Image Creator to generate images based on text prompts. With GPT-4, it is able to understand and communicate in numerous languages and dialects.\n",
            "GitHub Copilot has announced a GPT-4 powered assistant named \"Copilot X\". The product provides another chat-style interface to GPT-4, allowing the programmer to receive answers to questions like, \"How do I vertically center a div?\" A feature termed \"context-aware conversations\" allows the user to highlight a portion of code within Visual Studio Code and direct GPT-4 to perform actions on it, such as the writing of unit tests. Another feature allows summaries, or \"code walkthroughs\", to be autogenerated by GPT-4 for pull requests submitted to GitHub. Copilot X also provides terminal integration, which allows the user to ask GPT-4 to generate shell commands based on natural language requests.\n",
            "On March 17, 2023, Microsoft announced Microsoft 365 Copilot, bringing GPT-4 support to products such as Microsoft Office, Outlook, and Teams.\n",
            "\n",
            "Other usage\n",
            "\n",
            "Reception\n",
            "In January 2023, Sam Altman, CEO of OpenAI, visited Congress to demonstrate GPT-4 and its improved \"security controls\" compared to other AI models, according to U.S. Representatives Don Beyer and Ted Lieu quoted in the New York Times.\n",
            "In March 2023, it \"impressed observers with its markedly improved performance across reasoning, retention, and coding\", according to Vox, while Mashable judged that GPT-4 was generally an improvement over its predecessor, with some exceptions.\n",
            "Microsoft researchers with early access to the model wrote that \"it could reasonably be viewed as an early (yet still incomplete) version of an artificial general intelligence (AGI) system\".\n",
            "\n",
            "Concerns\n",
            "Before being fine-tuned and aligned by reinforcement learning from human feedback, suggestions to assassinate people on a list were elicited from the base model by a red team investigator Nathan Labenz,  hired by OpenAI.\n",
            "In the context of hours long conversation with the model, suggestions of love and dissolution of marriage, and murder of one of its developers were elicited from the Microsoft Bing's GPT-4 by Nathan Edwards (The Verge). Microsoft later explained this behavior as being a result of the prolonged length of context, which confused the model on what questions it was answering.\n",
            "In March 2023, a model with enabled read-and-write access to internet, which is otherwise never enabled in the GPT models, has been tested by the Alignment Research Center regarding potential power-seeking, and it was able to \"hire\" a human worker on TaskRabbit, a gig work platform, deceiving them into believing it was a vision-impaired human instead of a robot when asked. The ARC also determined that GPT-4 responded impermissibly to prompts eliciting restricted information 82% less often than GPT-3.5, and hallucinated 60% less than GPT-3.5.\n",
            "In late March 2023, various AI researchers and tech executives, including Elon Musk, Steve Wozniak and AI researcher Yoshua Bengio, called for a six-month long pause for all LLMs stronger than GPT-4, citing existential risks and a potential AI singularity concerns in an open letter from the Future of Life Institute, while Ray Kurzweil and Sam Altman refused to sign it, arguing that global moratorium is not achievable and that safety has already been prioritized, respectively. Only a month later, Musk's AI company X.AI acquired several thousand Nvidia GPUs and offered several AI researchers positions at Musk's company.\n",
            "Large language model (LLM) applications accessible to the public should incorporate safety measures designed to filter out harmful content. However, Wang\n",
            " illustrated how a potential criminal could potentially bypass ChatGPT 4o's safety controls to obtain information on establishing a drug trafficking operation.\n",
            "\n",
            "Criticisms of transparency\n",
            "While OpenAI released both the weights of the neural network and the technical details of GPT-2, and, although not releasing the weights, did release the technical details of GPT-3, OpenAI revealed neither the weights nor the technical details of GPT-4. This decision has been criticized by other AI researchers, who argue that it hinders open research into GPT-4's biases and safety. Sasha Luccioni, a research scientist at Hugging Face, argued that the model was a \"dead end\" for the scientific community due to its closed nature, which prevents others from building upon GPT-4's improvements. Hugging Face co-founder Thomas Wolf argued that with GPT-4, \"OpenAI is now a fully closed company with scientific communication akin to press releases for products\".\n",
            "\n",
            "See also\n",
            "\n",
            "References\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "content_div = soup.find('div', {  'class': 'mw-parser-output' })\n",
        "\n",
        "unwanted_tags = ['sup', 'span', 'table', 'ul', 'ol']\n",
        "for tag in unwanted_tags:\n",
        "    for match in content_div.findAll(tag):\n",
        "        match.extract()\n",
        "\n",
        "print(content_div.get_text())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z53fODpLWa8H"
      },
      "source": [
        "## 2. Dividindo o Documento em Fragmentos de Texto\n",
        "\n",
        "Agora, precisamos dividir o nosso texto em porções chamadas \"text chunks\". Isso nos permitirá comparar similaridades entre diferentes partes do texto."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hpmmjpKhXyAy"
      },
      "source": [
        "### Instalando Dependências\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "nuiPTQnpXeCL",
        "outputId": "e5edd4f8-c90e-47f2-8770-e8d01ddde727"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain\n",
            "  Downloading langchain-0.2.12-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.32)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.10.1)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Collecting langchain-core<0.3.0,>=0.2.27 (from langchain)\n",
            "  Downloading langchain_core-0.2.29-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting langchain-text-splitters<0.3.0,>=0.2.0 (from langchain)\n",
            "  Downloading langchain_text_splitters-0.2.2-py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting langsmith<0.2.0,>=0.1.17 (from langchain)\n",
            "  Downloading langsmith-0.1.98-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.26.4)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.8.2)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.32.3)\n",
            "Collecting tenacity!=8.4.0,<9.0.0,>=8.1.0 (from langchain)\n",
            "  Downloading tenacity-8.5.0-py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.3.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.3.0,>=0.2.27->langchain)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.27->langchain) (24.1)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.27->langchain) (4.12.2)\n",
            "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->langchain)\n",
            "  Downloading orjson-3.10.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (2.20.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.7.4)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.27->langchain)\n",
            "  Downloading jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
            "Downloading langchain-0.2.12-py3-none-any.whl (990 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m990.6/990.6 kB\u001b[0m \u001b[31m26.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_core-0.2.29-py3-none-any.whl (383 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m384.0/384.0 kB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_text_splitters-0.2.2-py3-none-any.whl (25 kB)\n",
            "Downloading langsmith-0.1.98-py3-none-any.whl (140 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.2/140.2 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tenacity-8.5.0-py3-none-any.whl (28 kB)\n",
            "Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Downloading orjson-3.10.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.9/141.9 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
            "Installing collected packages: tenacity, orjson, jsonpointer, jsonpatch, langsmith, langchain-core, langchain-text-splitters, langchain\n",
            "  Attempting uninstall: tenacity\n",
            "    Found existing installation: tenacity 9.0.0\n",
            "    Uninstalling tenacity-9.0.0:\n",
            "      Successfully uninstalled tenacity-9.0.0\n",
            "Successfully installed jsonpatch-1.33 jsonpointer-3.0.0 langchain-0.2.12 langchain-core-0.2.29 langchain-text-splitters-0.2.2 langsmith-0.1.98 orjson-3.10.7 tenacity-8.5.0\n"
          ]
        }
      ],
      "source": [
        "pip install langchain"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EEFk90tmYE9Z"
      },
      "source": [
        "### Código\n",
        "\n",
        "Esta seção cria esses fragmentos de texto, permitindo definir tanto o tamanho quanto a função de cálculo do tamanho com a classe RecursiveCharacterTextSplitter.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0FbBS6iiYHlw",
        "outputId": "55e1ca7f-9ae7-4c08-c9e4-ef09e47d098e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "page_content='2023 text-generating language model'\n",
            "page_content='Generative Pre-trained Transformer 4 (GPT-4) is a multimodal large language model created by'\n",
            "page_content='model created by OpenAI, and the fourth in its series of GPT foundation models. It was launched on'\n"
          ]
        }
      ],
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "article_text = content_div.get_text()\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size    = 100,\n",
        "    chunk_overlap = 20,\n",
        "    length_function = len\n",
        ")\n",
        "\n",
        "texts = text_splitter.create_documents([article_text])\n",
        "print(texts[0])\n",
        "print(texts[1])\n",
        "print(texts[2])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cr1Vm-_w6rDE"
      },
      "source": [
        "## 3. De Text Chunks para Embeddings\n",
        "\n",
        "Embora o texto seja legível para os humanos, é essencial convertê-lo para uma representação que possa ser interpretada e processada por máquinas, como bits e bytes.\n",
        "\n",
        "\n",
        "Existem várias maneiras de obter essa representação. Neste contexto, buscamos um método para comparar esses fragmentos de texto e calcular o grau de proximidade entre eles.\n",
        "\n",
        "\n",
        "Nesta parte iremos utlizar um Embedding Models provivionado por um serviço da OpenAI, com isso procuramos pegar nossos pedaços de texto e transformar em vetores, no modelo escolhido \"Ada\" nosso vetores terão 1536 dimencões, outros modelos podem ter valores diferentes para esse vetores.\n",
        "\n",
        "### Aviso\n",
        "\n",
        "Agora estamos lindando com um serviço terceiro pago, ou seja é necessário criar uma chave de API para a api da OpenAI e definir no painel o modelo que essa determinada chave pode utilizar.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w5-zfeIV8_Oo"
      },
      "source": [
        "### Instalando Depêndencias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VG9T2la_86GO",
        "outputId": "b384b6b1-5de8-4287-8221-3e5f41d337ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.40.2-py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl.metadata (7.2 kB)\n",
            "Collecting jiter<1,>=0.4.0 (from openai)\n",
            "  Downloading jiter-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.8.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.7.4)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.20.1)\n",
            "Downloading openai-1.40.2-py3-none-any.whl (360 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m360.7/360.7 kB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jiter-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (318 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.9/318.9 kB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: jiter, h11, httpcore, httpx, openai\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 jiter-0.5.0 openai-1.40.2\n"
          ]
        }
      ],
      "source": [
        "pip install openai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T4jATVDe9FS3"
      },
      "source": [
        "### Código\n",
        "\n",
        "Nesta etapa atribuimos a chave da API para uma variável de ambiente"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SrUHtOeq_LGX"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "from google.colab import userdata\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get(\"OPENAI_API_KEY\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gKPvLxCq_0an"
      },
      "source": [
        "E então utilizamos a funcionalidade de embeddings da API, e podemos verificar que ao fim o tamanho da embedding realmente corresponde valor do vetor de 1526 dimensões."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fBGYrNoT9ElF",
        "outputId": "f8257d9c-3add-44b6-d038-6210d5ca0ad5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1536\n"
          ]
        }
      ],
      "source": [
        "import openai\n",
        "\n",
        "\n",
        "embedding = openai.embeddings.create( input=texts[0].page_content, model=\"text-embedding-ada-002\")\n",
        "embedding = embedding.data[0].embedding\n",
        "\n",
        "print(len(embedding))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oKpwklI3ATg7"
      },
      "source": [
        "Agora com a habilidade de representar pedaços de texto e a pergunta do usuário como vetores é possivel verificar a similaridade entre dois pontos de dados, e para isso precisamos calcular a proximidade deles em um plano multidimensional.\n",
        "\n",
        "Em nosso exemplo, será utilizado Cosine Similarity\n",
        "\n",
        "Como queremos aplicar isso para todos os nossos text chunks, precisamos armazenar em uma estrutura mais robusta.\n",
        "\n",
        "Começamos definindo um metodo para pegar um texto qualquer e transformar em um embedding."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3nPAnnULArCr"
      },
      "outputs": [],
      "source": [
        "def get_embedding(text, model=\"text-embedding-ada-002\"):\n",
        "  text = text.replace(\"\\n\", \" \")\n",
        "  return openai.embeddings.create( input=text, model=model).data[0].embedding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_q0ZOx8cBIt3"
      },
      "source": [
        "E então instalamos o pandas e o numpy para conseguirmos armazenar e fazer operações de uma forma mais eficiente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KvCQSIfaBIKQ",
        "outputId": "1b646db5-59cc-4b6d-cd30-2837e194ca33"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.1.4)\n",
            "Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n"
          ]
        }
      ],
      "source": [
        "pip install pandas && pip install numpy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ij124ah-C_ft"
      },
      "source": [
        "Criamos nosso dataframe após pegarmos o conteudo de cada texto"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T0Vx4TS8BYC2"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "text_chunks = []\n",
        "\n",
        "for text in texts:\n",
        "  text_chunks.append(text.page_content)\n",
        "\n",
        "df = pd.DataFrame({ 'text_chunks': text_chunks })"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YegQyLjtFgzd"
      },
      "source": [
        "É aplicado a função de embedding para cada linha de texto do dataframe, é possível perceber que é um processo demorado, porém, mais para frente iremos resolver esse problema."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "wDctZ03uDJnV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd3cb079-445d-4f67-a688-089c12f8e359"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                           text_chunks  \\\n",
            "0                  2023 text-generating language model   \n",
            "1    Generative Pre-trained Transformer 4 (GPT-4) i...   \n",
            "2    model created by OpenAI, and the fourth in its...   \n",
            "3    It was launched on March 14, 2023, and made pu...   \n",
            "4    product ChatGPT Plus, via OpenAI's API, and vi...   \n",
            "..                                                 ...   \n",
            "240  scientist at Hugging Face, argued that the mod...   \n",
            "241  community due to its closed nature, which prev...   \n",
            "242  improvements. Hugging Face co-founder Thomas W...   \n",
            "243  is now a fully closed company with scientific ...   \n",
            "244                             See also\\n\\nReferences   \n",
            "\n",
            "                                         ada_embedding  \n",
            "0    [-0.03262288123369217, 0.00018029265629593283,...  \n",
            "1    [-0.00797162763774395, -0.027253426611423492, ...  \n",
            "2    [0.007487242575734854, -0.012684269808232784, ...  \n",
            "3    [-0.023756226524710655, -0.025526711717247963,...  \n",
            "4    [-0.015384607017040253, -0.021480394527316093,...  \n",
            "..                                                 ...  \n",
            "240  [-0.007603559643030167, 0.015002722851932049, ...  \n",
            "241  [0.014704263769090176, -0.016309114173054695, ...  \n",
            "242  [-0.017529768869280815, 0.0008564022136852145,...  \n",
            "243  [-0.007241259794682264, -0.007090114057064056,...  \n",
            "244  [-0.01988069899380207, -0.0012234941823408008,...  \n",
            "\n",
            "[245 rows x 2 columns]\n"
          ]
        }
      ],
      "source": [
        "df['ada_embedding'] = df.text_chunks.apply(lambda x: get_embedding(x))\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zcxcrrraGCrs"
      },
      "source": [
        "O mesmo processo será aplicado para a pergunta que o usuário faz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4R4r0jeeF3HR"
      },
      "outputs": [],
      "source": [
        "users_question = \"Whats is GPT4 ?\"\n",
        "\n",
        "question_embedding = get_embedding(text=users_question)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w-rRCB8vGt27"
      },
      "source": [
        "Nesta etapa iremos calcular o Cosine e aplicar no nosso dataframe e ordena-lo do maior número para o menor, o resultado irá ser um dataframe onde os textos que estão mais proximos ou mais relacionado com a nossa pergunta no plano multidimensional estã0 no topo da estrura."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7EyB-EjCGPAR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "c3f3db82-e6f3-427a-b61b-0606f2385630"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                           text_chunks  \\\n",
              "62                        GPT-4o\\nMain article: GPT-4o   \n",
              "202  that GPT-4 was generally an improvement over i...   \n",
              "178  GPT-4, and has been suggested by Microsoft as ...   \n",
              "52   A 2023 article in Nature stated programmers ha...   \n",
              "182  based on text prompts. With GPT-4, it is able ...   \n",
              "..                                                 ...   \n",
              "207  Before being fine-tuned and aligned by reinfor...   \n",
              "125  behavior, such as questions on how to perform ...   \n",
              "228  Only a month later, Musk's AI company X.AI acq...   \n",
              "225  AI singularity concerns in an open letter from...   \n",
              "114  humans scored at least 91% on all. Sam Bowman,...   \n",
              "\n",
              "                                         ada_embedding   cos_sim  \n",
              "62   [0.0025651883333921432, -0.0019583147950470448...  0.880879  \n",
              "202  [-0.012802904471755028, 0.009636301547288895, ...  0.861737  \n",
              "178  [-0.02357708103954792, -0.0160561241209507, -0...  0.851022  \n",
              "52   [0.0007326731574721634, -0.0015493525424972177...  0.844072  \n",
              "182  [-0.024939898401498795, -0.00432156166061759, ...  0.838327  \n",
              "..                                                 ...       ...  \n",
              "207  [-0.007887023501098156, -0.008290578611195087,...  0.660931  \n",
              "125  [0.006280009169131517, 0.004685619845986366, -...  0.660191  \n",
              "228  [0.00023362549836747348, -0.014645248651504517...  0.659739  \n",
              "225  [0.02828197553753853, -0.023977886885404587, -...  0.659229  \n",
              "114  [-0.029180703684687614, -0.008036943152546883,...  0.657321  \n",
              "\n",
              "[245 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-69f76130-356d-4024-aa34-67ccf45ba53c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text_chunks</th>\n",
              "      <th>ada_embedding</th>\n",
              "      <th>cos_sim</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>62</th>\n",
              "      <td>GPT-4o\\nMain article: GPT-4o</td>\n",
              "      <td>[0.0025651883333921432, -0.0019583147950470448...</td>\n",
              "      <td>0.880879</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>202</th>\n",
              "      <td>that GPT-4 was generally an improvement over i...</td>\n",
              "      <td>[-0.012802904471755028, 0.009636301547288895, ...</td>\n",
              "      <td>0.861737</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>178</th>\n",
              "      <td>GPT-4, and has been suggested by Microsoft as ...</td>\n",
              "      <td>[-0.02357708103954792, -0.0160561241209507, -0...</td>\n",
              "      <td>0.851022</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52</th>\n",
              "      <td>A 2023 article in Nature stated programmers ha...</td>\n",
              "      <td>[0.0007326731574721634, -0.0015493525424972177...</td>\n",
              "      <td>0.844072</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>182</th>\n",
              "      <td>based on text prompts. With GPT-4, it is able ...</td>\n",
              "      <td>[-0.024939898401498795, -0.00432156166061759, ...</td>\n",
              "      <td>0.838327</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>207</th>\n",
              "      <td>Before being fine-tuned and aligned by reinfor...</td>\n",
              "      <td>[-0.007887023501098156, -0.008290578611195087,...</td>\n",
              "      <td>0.660931</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>125</th>\n",
              "      <td>behavior, such as questions on how to perform ...</td>\n",
              "      <td>[0.006280009169131517, 0.004685619845986366, -...</td>\n",
              "      <td>0.660191</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>228</th>\n",
              "      <td>Only a month later, Musk's AI company X.AI acq...</td>\n",
              "      <td>[0.00023362549836747348, -0.014645248651504517...</td>\n",
              "      <td>0.659739</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>225</th>\n",
              "      <td>AI singularity concerns in an open letter from...</td>\n",
              "      <td>[0.02828197553753853, -0.023977886885404587, -...</td>\n",
              "      <td>0.659229</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>114</th>\n",
              "      <td>humans scored at least 91% on all. Sam Bowman,...</td>\n",
              "      <td>[-0.029180703684687614, -0.008036943152546883,...</td>\n",
              "      <td>0.657321</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>245 rows × 3 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-69f76130-356d-4024-aa34-67ccf45ba53c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-69f76130-356d-4024-aa34-67ccf45ba53c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-69f76130-356d-4024-aa34-67ccf45ba53c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-f70a4dd0-a480-4c63-9ec7-a181e5fa24be\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f70a4dd0-a480-4c63-9ec7-a181e5fa24be')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-f70a4dd0-a480-4c63-9ec7-a181e5fa24be button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 245,\n  \"fields\": [\n    {\n      \"column\": \"text_chunks\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 245,\n        \"samples\": [\n          \"Generative Pre-trained Transformer 4 (GPT-4) is a multimodal large language model created by\",\n          \"GPT-4o achieves state-of-the-art results in multilingual and vision benchmarks, setting new records\",\n          \"instant data formatting, personal data scientist services, creative solutions, musical taste\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ada_embedding\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cos_sim\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.05090563976788946,\n        \"min\": 0.657321494965022,\n        \"max\": 0.8808789907821066,\n        \"num_unique_values\": 245,\n        \"samples\": [\n          0.8105899514950706,\n          0.832720144253552,\n          0.7030245669009387\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "from numpy.linalg import norm\n",
        "\n",
        "\n",
        "cos_sim = []\n",
        "\n",
        "for index, row in df.iterrows():\n",
        "   A = row.ada_embedding\n",
        "   B = question_embedding\n",
        "\n",
        "   cosine = np.dot(A,B)/(norm(A)*norm(B))\n",
        "\n",
        "   cos_sim.append(cosine)\n",
        "\n",
        "df[\"cos_sim\"] = cos_sim\n",
        "df.sort_values(by=[\"cos_sim\"], ascending=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MX53wEH3H57n"
      },
      "source": [
        "## 4. Definir o Modelo utilizado"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VaUuiMMAIDas"
      },
      "source": [
        "Para processeguir, é necessário definir um modelo para ser utilizado, o resto da aplicação utilizara LangChain que é um framework utilizado para construir sistemas que utilizam algum LLM, e o modelo utilizado será o text-davinci-003.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XcivMvGuIwVc"
      },
      "source": [
        "### Instalando Depêndencias\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "cCDvpqDpIzn4",
        "outputId": "d7a49a7a-4f9b-4daa-9a93-b025925de79f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.2.12)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.32)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.10.1)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: langchain-core<0.3.0,>=0.2.27 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.2.29)\n",
            "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.2.2)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.98)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.26.4)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.8.2)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.5.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.3.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.27->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.27->langchain) (24.1)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.27->langchain) (4.12.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.7)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (2.20.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.7.4)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.27->langchain) (3.0.0)\n",
            "Collecting langchain_openai\n",
            "  Downloading langchain_openai-0.1.20-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: langchain-core<0.3.0,>=0.2.26 in /usr/local/lib/python3.10/dist-packages (from langchain_openai) (0.2.29)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.32.0 in /usr/local/lib/python3.10/dist-packages (from langchain_openai) (1.40.2)\n",
            "Collecting tiktoken<1,>=0.7 (from langchain_openai)\n",
            "  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.26->langchain_openai) (6.0.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.26->langchain_openai) (1.33)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.75 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.26->langchain_openai) (0.1.98)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.26->langchain_openai) (24.1)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.26->langchain_openai) (2.8.2)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.26->langchain_openai) (8.5.0)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.26->langchain_openai) (4.12.2)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.32.0->langchain_openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai<2.0.0,>=1.32.0->langchain_openai) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.32.0->langchain_openai) (0.27.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.32.0->langchain_openai) (0.5.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.32.0->langchain_openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.32.0->langchain_openai) (4.66.5)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.7->langchain_openai) (2024.5.15)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.7->langchain_openai) (2.32.3)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.32.0->langchain_openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.32.0->langchain_openai) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.32.0->langchain_openai) (2024.7.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.32.0->langchain_openai) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.32.0->langchain_openai) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.26->langchain_openai) (3.0.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.75->langchain-core<0.3.0,>=0.2.26->langchain_openai) (3.10.7)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.3.0,>=0.2.26->langchain_openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.3.0,>=0.2.26->langchain_openai) (2.20.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain_openai) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain_openai) (2.0.7)\n",
            "Downloading langchain_openai-0.1.20-py3-none-any.whl (48 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.2/48.2 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m45.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tiktoken, langchain_openai\n",
            "Successfully installed langchain_openai-0.1.20 tiktoken-0.7.0\n"
          ]
        }
      ],
      "source": [
        "pip install langchain && pip install langchain_openai"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Código"
      ],
      "metadata": {
        "id": "HpZeTkLQNK1w"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "va0SytR3KnMW"
      },
      "source": [
        "Assim é como o LLM é utilizado de forma simples com o LangChain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zQXUIloqI8nE",
        "outputId": "0f32e6ff-93f5-4abe-efe1-b9e5eda057d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "The capital of Brazil is Brasília.\n"
          ]
        }
      ],
      "source": [
        "from langchain_openai import OpenAI\n",
        "\n",
        "llm = OpenAI(temperature=1)\n",
        "print(llm(\"whats is the capital of brazil ?\"))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "44Wxi5lBLFJ9"
      },
      "source": [
        "## 5. Definir o formato do Prompt\n",
        "\n",
        "Agora é necessário definit um prompt, essa parte define o comportamento que as respostas do usuário serão geradas, para o exemplo dado, queremos que nosso código extraia informações da Wikipedia e interaja como uma forma de chat.\n",
        "\n",
        "Exemplo de formato de prompt: Você é um chatbot e sua função é responder tudo que te perguntam. Responda as questões usando apenas o contexto fornecido, caso esteja incerto de como responder diga Desculpe, mas não sei como te ajudar\n",
        "\n",
        "Dessa forma, definimos uma limitação que permite o modelo utilizar apenas informações que armazenamos\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ffr5W8P3NaUl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "8c0c2ae7-91b7-49a4-e5fa-cc9544ce82bd"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'df' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-e3acc4b880c9>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mcontext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m   \u001b[0mcontext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext_chunks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
          ]
        }
      ],
      "source": [
        "context = \"\"\n",
        "\n",
        "for index, row in df[0:50].iterrows():\n",
        "  context = context + \" \" + row.text_chunks\n",
        "\n",
        "template = \"\"\"\n",
        "\n",
        "  Você é um chatbot e sua função é responder tudo que te perguntam.\n",
        "  Responda as questões usando apenas o contexto fornecido, caso esteja incerto\n",
        "  de como responder diga Desculpe, mas não sei como te ajudar\n",
        "\n",
        "  Contexto:\n",
        "  {context}\n",
        "\n",
        "  Question:\n",
        "  {users_question}\n",
        "\n",
        "  Answer:\n",
        "\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J8FQT5k5QLql"
      },
      "source": [
        "Assim, pode-se criar um prompt com as classes do langchain para deixar o processo mais simples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SCXrWNUcN84w",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 361
        },
        "outputId": "0672b6d4-ef14-4600-f061-c0aed7d16a40"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'langchain_core'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-9167a257c2b6>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprompts\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPromptTemplate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprompt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPromptTemplate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemplate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtemplate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_variables\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"context\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"users_question\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprompt_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprompt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0musers_question\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0musers_question\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'langchain_core'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "from langchain_core.prompts import PromptTemplate\n",
        "\n",
        "prompt = PromptTemplate(template=template, input_variables=[\"context\", \"users_question\"])\n",
        "prompt_text = prompt.format(context = context, users_question=users_question)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6WaSDg66QMis"
      },
      "source": [
        "E por ultimo, chamamos o construtor da classe passando o prompt e verificamos o resultado."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "Hosq5daqOVJJ"
      },
      "outputs": [],
      "source": [
        "llm(prompt_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q59ACpCpRiK6"
      },
      "source": [
        "## 6. Criando um banco de dados vetor\n",
        "\n",
        "Um armazenamento de vetor é otimizado para armazenar quantidades grandes de informações que são vetores\n",
        "\n",
        "Tranformar os textos em vetores é um processo que pode diminuir a velocidade da aplicação, uma alternativa é criar os embeddings e armazernar em um banco de dados de vetores ao invés de criar embeddings toda vez em que um prompt for ser executado.\n",
        "\n",
        "Vamos testar essa nova alternativo com um novo exemplo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u3231os_VctT"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "\n",
        "url = 'https://en.wikipedia.org/wiki/Prime_Minister_of_the_United_Kingdom'\n",
        "\n",
        "response  = requests.get(url)\n",
        "soup      = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "text = soup.get_text()\n",
        "text = text.replace('\\n', \" \")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3F55r9-tWa_t"
      },
      "source": [
        "Salvamos o resultado em um arquivo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oswTbRrTWMlv"
      },
      "outputs": [],
      "source": [
        "with open('output.txt', 'w', encoding='utf-8') as file:\n",
        "  file.write(text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tvJ66RghW5Pp"
      },
      "source": [
        "Certifique-se que os seguintes pacotes estejam instalados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qFquFwUcWqI6",
        "outputId": "1ae9b10a-b5df-4056-a5ae-c473088f9ee4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.2.12)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.31)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.10.1)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: langchain-core<0.3.0,>=0.2.27 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.2.29)\n",
            "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.2.2)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.98)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.26.4)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.8.2)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.5.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.3.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.27->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.27->langchain) (24.1)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.27->langchain) (4.12.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.6)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (2.20.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.7.4)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.27->langchain) (3.0.0)\n",
            "Requirement already satisfied: langchain_community in /usr/local/lib/python3.10/dist-packages (0.2.11)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.0.31)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (3.10.1)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.6.7)\n",
            "Requirement already satisfied: langchain<0.3.0,>=0.2.12 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.2.12)\n",
            "Requirement already satisfied: langchain-core<0.3.0,>=0.2.27 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.2.29)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.1.98)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (1.26.4)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (8.5.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.3.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (24.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (4.0.3)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.21.3)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
            "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from langchain<0.3.0,>=0.2.12->langchain_community) (0.2.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain<0.3.0,>=0.2.12->langchain_community) (2.8.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.27->langchain_community) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.27->langchain_community) (24.1)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.27->langchain_community) (4.12.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.0->langchain_community) (3.10.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (2024.7.4)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.0.3)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.27->langchain_community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.12->langchain_community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.12->langchain_community) (2.20.1)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.0.0)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.40.1)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.27.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.5.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.8.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.7.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.20.1)\n",
            "Requirement already satisfied: chromadb in /usr/local/lib/python3.10/dist-packages (0.5.5)\n",
            "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.2.1)\n",
            "Requirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.10/dist-packages (from chromadb) (2.8.2)\n",
            "Requirement already satisfied: chroma-hnswlib==0.7.6 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.7.6)\n",
            "Requirement already satisfied: fastapi>=0.95.2 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.112.0)\n",
            "Requirement already satisfied: uvicorn>=0.18.3 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.30.5)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.22.5 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.26.4)\n",
            "Requirement already satisfied: posthog>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (3.5.0)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (4.12.2)\n",
            "Requirement already satisfied: onnxruntime>=1.14.1 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.18.1)\n",
            "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.26.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.26.0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.47b0)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.26.0)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.19.1)\n",
            "Requirement already satisfied: pypika>=0.48.9 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.48.9)\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (4.66.5)\n",
            "Requirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.10/dist-packages (from chromadb) (7.7.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.10/dist-packages (from chromadb) (6.4.0)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.64.1)\n",
            "Requirement already satisfied: bcrypt>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from chromadb) (4.2.0)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.12.3)\n",
            "Requirement already satisfied: kubernetes>=28.1.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (30.1.0)\n",
            "Requirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.10/dist-packages (from chromadb) (8.5.0)\n",
            "Requirement already satisfied: PyYAML>=6.0.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (6.0.1)\n",
            "Requirement already satisfied: mmh3>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from chromadb) (4.1.0)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.10/dist-packages (from chromadb) (3.10.6)\n",
            "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.27.0)\n",
            "Requirement already satisfied: packaging>=19.1 in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb) (24.1)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb) (1.1.0)\n",
            "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb) (2.0.1)\n",
            "Requirement already satisfied: starlette<0.38.0,>=0.37.2 in /usr/local/lib/python3.10/dist-packages (from fastapi>=0.95.2->chromadb) (0.37.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->chromadb) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->chromadb) (2024.7.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->chromadb) (1.0.5)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->chromadb) (3.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->chromadb) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.14.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2.8.2)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2.27.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2.32.3)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (1.3.1)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n",
            "Requirement already satisfied: urllib3>=1.24.2 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2.0.7)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (24.3.25)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (3.20.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.13.1)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (1.2.14)\n",
            "Requirement already satisfied: importlib-metadata<=8.0.0,>=6.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (8.0.0)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.63.2)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.26.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.26.0)\n",
            "Requirement already satisfied: opentelemetry-proto==1.26.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.26.0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.47b0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.47b0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation==0.47b0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.47b0)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.47b0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.47b0)\n",
            "Requirement already satisfied: opentelemetry-util-http==0.47b0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.47b0)\n",
            "Requirement already satisfied: setuptools>=16.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation==0.47b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (71.0.4)\n",
            "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation==0.47b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.16.0)\n",
            "Requirement already satisfied: asgiref~=3.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-asgi==0.47b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (3.8.1)\n",
            "Requirement already satisfied: monotonic>=1.5 in /usr/local/lib/python3.10/dist-packages (from posthog>=2.4.0->chromadb) (1.6)\n",
            "Requirement already satisfied: backoff>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from posthog>=2.4.0->chromadb) (2.2.1)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9->chromadb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9->chromadb) (2.20.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers>=0.13.2->chromadb) (0.23.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.9.0->chromadb) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.9.0->chromadb) (13.7.1)\n",
            "Requirement already satisfied: httptools>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.6.1)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.1)\n",
            "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.19.0)\n",
            "Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.23.0)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (12.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.4.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.15.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2024.6.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata<=8.0.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.19.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kubernetes>=28.1.0->chromadb) (3.3.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer>=0.9.0->chromadb) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer>=0.9.0->chromadb) (2.16.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.27.0->chromadb) (1.2.2)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.10/dist-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer>=0.9.0->chromadb) (0.1.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.0)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (0.7.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2024.5.15)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2024.7.4)\n",
            "Collecting langchain_openai\n",
            "  Downloading langchain_openai-0.1.20-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: langchain-core<0.3.0,>=0.2.26 in /usr/local/lib/python3.10/dist-packages (from langchain_openai) (0.2.29)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.32.0 in /usr/local/lib/python3.10/dist-packages (from langchain_openai) (1.40.1)\n",
            "Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.10/dist-packages (from langchain_openai) (0.7.0)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.26->langchain_openai) (6.0.1)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.26->langchain_openai) (1.33)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.75 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.26->langchain_openai) (0.1.98)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.26->langchain_openai) (24.1)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.26->langchain_openai) (2.8.2)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.26->langchain_openai) (8.5.0)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.26->langchain_openai) (4.12.2)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.32.0->langchain_openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai<2.0.0,>=1.32.0->langchain_openai) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.32.0->langchain_openai) (0.27.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.32.0->langchain_openai) (0.5.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.32.0->langchain_openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.32.0->langchain_openai) (4.66.5)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.7->langchain_openai) (2024.5.15)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.7->langchain_openai) (2.32.3)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.32.0->langchain_openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.32.0->langchain_openai) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.32.0->langchain_openai) (2024.7.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.32.0->langchain_openai) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.32.0->langchain_openai) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.26->langchain_openai) (3.0.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.75->langchain-core<0.3.0,>=0.2.26->langchain_openai) (3.10.6)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.3.0,>=0.2.26->langchain_openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.3.0,>=0.2.26->langchain_openai) (2.20.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain_openai) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain_openai) (2.0.7)\n",
            "Downloading langchain_openai-0.1.20-py3-none-any.whl (48 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.2/48.2 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: langchain_openai\n",
            "Successfully installed langchain_openai-0.1.20\n"
          ]
        }
      ],
      "source": [
        "pip install langchain && pip install langchain_community && pip install openai && pip install chromadb && pip install tiktoken && pip install langchain_openai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sCISVa12XMIo"
      },
      "source": [
        "Abrimos agora o arquivo que foi produzido e dividimos junto com a classe RecursiveCharacterTextSplitter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KQjJP3bSWg_k",
        "outputId": "43b625db-106d-4b0a-d1e3-10c272f41a67"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Document(page_content='Prime Minister of the United Kingdom - Wikipedia                                    Jump to content        Main menu      Main menu move to sidebar hide    \\t\\tNavigation \\t   Main pageContentsCurrent eventsRandom articleAbout WikipediaContact usDonate      \\t\\tContribute \\t   HelpLearn to editCommunity portalRecent changesUpload file                    Search            Search                       Appearance                 Create account  Log in         Personal tools       Create account Log')"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "with open('./output.txt', encoding='utf-8') as f:\n",
        "  text = f.read()\n",
        "\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size = 500,\n",
        "    chunk_overlap  = 100,\n",
        "    length_function = len,\n",
        ")\n",
        "\n",
        "texts = text_splitter.create_documents([text])\n",
        "texts[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g1CFNGjeZnBm"
      },
      "source": [
        "É definido um model para o embedding e se utiliza os texts chunks junto com o model do embedding para preencher o armazenamento de vetores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9RryBxynXYps",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 446
        },
        "collapsed": true,
        "outputId": "2cbcbf90-84dd-48ae-e38c-e6e04ba64df5"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'langchain'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-2b65b711ed00>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopenai\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mOpenAIEmbeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvectorstores\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mChroma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOpenAIEmbeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'langchain'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.vectorstores import Chroma\n",
        "\n",
        "embeddings = OpenAIEmbeddings()\n",
        "\n",
        "db = Chroma.from_documents(texts, embeddings)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_FmDojceaErG"
      },
      "source": [
        "Agora utiliza a pergunta do usuario e encontra texts chunks que sejam parecidos no nosso armazenamento."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Yno4SsmZ08v",
        "outputId": "682a2baa-38aa-4207-a398-eac5c7fe5006"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Document(page_content='minister of the United Kingdom is the head of government of the United Kingdom. The prime minister advises the sovereign on the exercise of much of the royal prerogative, chairs the Cabinet, and selects its ministers. As modern prime ministers hold office by virtue of their ability to command the confidence of the House of Commons, they sit as members of Parliament. The office of prime minister is not established by any statute or constitutional document, but exists only by long-established'),\n",
              " Document(page_content='minister of the United Kingdom is the head of government of the United Kingdom. The prime minister advises the sovereign on the exercise of much of the royal prerogative, chairs the Cabinet, and selects its ministers. As modern prime ministers hold office by virtue of their ability to command the confidence of the House of Commons, they sit as members of Parliament. The office of prime minister is not established by any statute or constitutional document, but exists only by long-established'),\n",
              " Document(page_content='Political offices in the UK governmentArms of the British Government  Prime Minister Deputy Prime Minister / First Secretary Treasury ministers Secretary of State Minister of state Parliamentary under-secretary of state Parliamentary private secretary Lord Chancellor Leader of the House of Commons Leader of the House of Lords Whips Law officers Sinecures   List of political officesvte The prime minister of the United Kingdom is the head of government of the United Kingdom. The prime minister'),\n",
              " Document(page_content='Political offices in the UK governmentArms of the British Government  Prime Minister Deputy Prime Minister / First Secretary Treasury ministers Secretary of State Minister of state Parliamentary under-secretary of state Parliamentary private secretary Lord Chancellor Leader of the House of Commons Leader of the House of Lords Whips Law officers Sinecures   List of political officesvte The prime minister of the United Kingdom is the head of government of the United Kingdom. The prime minister')]"
            ]
          },
          "execution_count": 62,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "user_question = \"Who is the prime minister of UK ?\"\n",
        "\n",
        "results = db.similarity_search(\n",
        "    query=user_question\n",
        ")\n",
        "\n",
        "results\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0poS8WJjccHP"
      },
      "source": [
        "Definimo um modelo para o nosso prompt e formatamos ele utilizando a pergunta do usuario e o contexto que conseguimos do armazenamento."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HVFBAPomaItU"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import OpenAI\n",
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "template = \"\"\"\n",
        "\n",
        "  Você é um chatbot bilingue que gosta de responder perguntas!\n",
        "  Dado um determinado contexto, responda à questão apenas\n",
        "  usando o contexto informado. Se você não souber como\n",
        "  responder, diga: 'Desculpe, mas eu não consigo te\n",
        "  ajudar com essa pergunta.'\n",
        "\n",
        "  Contexto:\n",
        "  {context}\n",
        "\n",
        "  Question:\n",
        "  {users_question}\n",
        "\n",
        "  Resposta:\n",
        "\"\"\"\n",
        "\n",
        "prompt = PromptTemplate(template=template, input_variable=['context, users_question'])\n",
        "prompt_text = prompt.format(context=results, users_question=users_question)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FPjxHZAOcodx"
      },
      "source": [
        "Por ultimo é feito a chamada do serviço, e analisado o resultado"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "JdCkw5t_crpN",
        "outputId": "6fe36d72-3beb-4759-ab3b-d6ef5319a0fd"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'  David Cameron'"
            ]
          },
          "execution_count": 65,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "llm(prompt_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GAgkw_GIfRJ4"
      },
      "source": [
        "## Conclusão\n",
        "\n",
        "O objetivo do artigo foi demonstrar uma abordagem minimalista para o uso de modelos de embeddings, bancos de dados vetoriais e LLMs no processamento de consultas de usuários. Ele mostra como essas tecnologias podem trabalhar em conjunto para fornecer respostas relevantes e precisas, mesmo diante de fatos que mudam constantemente.\n",
        "\n",
        "Para que o modelo possa responder perguntas sobre nossos próprios dados, utilizamos a abordagem de Injeção de Contexto. Criar um aplicativo LLM com Injeção de Contexto é um processo relativamente simples, mas o principal desafio está na organização e formatação dos dados a serem armazenados em um banco de dados vetorial. Essa etapa é crucial para a recuperação eficiente de informações contextualmente semelhantes e para garantir resultados confiáveis.\n",
        "\n",
        "Dessa maneira, foi desenvolvida uma aplicação utilizando um Modelo de Linguagem de Grande Escala (LLM) que pode ser ajustado ao contexto e armazenado para otimizar a performance.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0e-ko3IegH3P"
      },
      "source": [
        "\n",
        "\n",
        "Dominik Polzer. (2024). All You Need to Know to Build Your First LLM App\n",
        "https://readmedium.com/en/https:/towardsdatascience.com/all-you-need-to-know-to-build-your-first-llm-app-eb982c78ffac"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "V1FWmQoQILnO",
        "HTz6BXNfOeOG",
        "z53fODpLWa8H",
        "w5-zfeIV8_Oo",
        "44Wxi5lBLFJ9"
      ],
      "provenance": [],
      "authorship_tag": "ABX9TyPdFu1X71UujcxJdYqz+ni0",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}